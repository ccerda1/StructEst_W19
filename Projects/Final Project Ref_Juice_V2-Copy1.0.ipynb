{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "import scipy.stats as sts\n",
    "import scipy.optimize as opt\n",
    "import numpy.linalg as lin\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening files, weeks to use are from 173 to 224 both included\n",
    "\n",
    "refj_mov = pd.read_stata(\"Dataset/WRFJ.DTA\")\n",
    "refj_upc = pd.read_csv('Dataset/upcrfj.csv', delimiter=',', header=0) \n",
    "upc_f = pd.ExcelFile(\"Dataset/UPC_LIST_RJ.xlsx\")\n",
    "upc_filtered = upc_f.parse(\"upcrfj\")\n",
    "demo = pd.read_stata(\"Dataset/demo.dta\")\n",
    "count = pd.read_stata(\"Dataset/ccount.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing data\n",
    "\n",
    "rj = refj_mov.loc[lambda rj: refj_mov.week<225, :]\n",
    "rjf = rj.loc[lambda rj2: rj.week>172, :]\n",
    "rjf_ok = rjf.loc[lambda rj3: rjf.ok==1, :]\n",
    "\n",
    "count2 = count.loc[:, lambda count: ['store', 'week', 'custcoun', 'date']]\n",
    "count3 = count2.loc[lambda count2: count2.week>172, :]\n",
    "countf = count3.loc[lambda count3: count3.week<225, :]\n",
    "\n",
    "demof = demo.loc[:, lambda demo: ['store', 'zone', 'income', 'AGE60', 'ethnic', 'hvalmean', 'shopindx', 'cubdist', 'omnidist', 'sstrdist', 'dtdist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "zones = demof.loc[lambda zones: demof.zone>=1,:]\n",
    "zones.dropna()\n",
    "zones.sort_values(by=['zone', 'store'])\n",
    "\n",
    "rjf_ok.loc[:,'zone']=rjf_ok['store'].map(zones.set_index('store')['zone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok.loc[:,'income']=rjf_ok['store'].map(zones.set_index('store')['income'])\n",
    "rjf_ok.loc[:,'AGE60']=rjf_ok['store'].map(zones.set_index('store')['AGE60'])\n",
    "rjf_ok.loc[:,'ethnic']=rjf_ok['store'].map(zones.set_index('store')['ethnic'])\n",
    "rjf_ok.loc[:,'hvalmean']=rjf_ok['store'].map(zones.set_index('store')['hvalmean'])\n",
    "rjf_ok.loc[:,'shopindx']=rjf_ok['store'].map(zones.set_index('store')['shopindx'])\n",
    "rjf_ok.loc[:,'cubdist']=rjf_ok['store'].map(zones.set_index('store')['cubdist'])\n",
    "rjf_ok.loc[:,'omnidist']=rjf_ok['store'].map(zones.set_index('store')['omnidist'])\n",
    "rjf_ok.loc[:,'sstrdist']=rjf_ok['store'].map(zones.set_index('store')['sstrdist'])\n",
    "rjf_ok.loc[:,'dtdist']=rjf_ok['store'].map(zones.set_index('store')['dtdist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok.loc[:,'desc']=rjf_ok['upc'].map(refj_upc.set_index('UPC')['Desc']).fillna(0)\n",
    "rjf_ok.loc[:,'OZ']=rjf_ok['upc'].map(refj_upc.set_index('UPC')['OZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countf.loc[:,'store-week'] = countf['store'].apply(lambda x: x*1000)+countf['week']\n",
    "countf_perweek = countf.groupby(['store','week','store-week'], as_index=False)['custcoun'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok.loc[:,'store-week'] = rjf_ok['store'].apply(lambda x: x*1000)+rjf_ok['week']\n",
    "rjf_ok.loc[:,'totcount']=rjf_ok['store-week'].map(countf_perweek.set_index('store-week')['custcoun']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok=rjf_ok.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_dummies_rj = pd.get_dummies(rjf_ok['sale'])\n",
    "promo_drj= promo_dummies_rj.B+promo_dummies_rj.G+promo_dummies_rj.S\n",
    "promo_drj=pd.DataFrame(promo_drj)\n",
    "promo_drj.columns=['promo']\n",
    "rjf_ok.loc[:,'promo']=promo_drj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rjf_ok.loc[:,'family']=round(rjf_ok.upc/1e6,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjfbrand_d = pd.get_dummies(rjf_ok['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjfbrand_d.columns = ['o1', 'florida', 'o2', 'MinMade', 'o3', 'Domm', 'o4', 'o5', 'o6', 'Tropic', 'o7', 'o8', 'o9','o10','o11','o12','o13','o14','o15','o16']\n",
    "rjfbrand_d2 = rjfbrand_d[['florida','MinMade','Domm','Tropic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok=pd.concat([rjf_ok,rjfbrand_d2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok['share'] = rjf_ok.move/rjf_ok.totcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = rjf_ok.move.sum()\n",
    "#all_d=lndf_ok.all_det[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida=rjf_ok.move*rjf_ok.florida\n",
    "MinMade=rjf_ok.move*rjf_ok.MinMade\n",
    "Domm=rjf_ok.move*rjf_ok.Domm\n",
    "Tropic=rjf_ok.move*rjf_ok.Tropic\n",
    "total=florida.sum()+MinMade.sum()+Domm.sum()+Tropic.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048737018585539846\n",
      "0.2867739930171557\n",
      "0.28701597428627396\n",
      "0.3774730141110305\n"
     ]
    }
   ],
   "source": [
    "print(florida.sum()/total)\n",
    "print(MinMade.sum()/total)\n",
    "print(Domm.sum()/total)\n",
    "print(Tropic.sum()/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dummies_rj = pd.get_dummies(rjf_ok['OZ'])\n",
    "#size_dummies_rj[' 64']\n",
    "size_64_d_rj = size_dummies_rj[' 64']\n",
    "rjf_ok=pd.concat([rjf_ok,size_64_d_rj], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rjf_ok=rjf_ok.drop([' 64'], axis=1)\n",
    "rjf_ok.rename(columns={' 64':'64_OZ'})\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok = rjf_ok.loc[lambda rj3: rjf_ok.move>0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida64 = upc_filtered.iloc[:2,:4]\n",
    "MinMade64 = upc_filtered.iloc[2:6,:4]\n",
    "MinMade96 = upc_filtered.iloc[6:8,:4]\n",
    "HH64 = upc_filtered.iloc[19:21,:4]\n",
    "HH128 = upc_filtered.iloc[21:,:4]\n",
    "TropPr64 = upc_filtered.iloc[14:16,:4]\n",
    "TropPr96 = upc_filtered.iloc[16,:4]\n",
    "TropSB64 = upc_filtered.iloc[17:19,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "florida64:  129325\n"
     ]
    }
   ],
   "source": [
    "florida64_d1=rjf_ok['upc'].isin(florida64['upc'])\n",
    "florida64_d2=pd.get_dummies(florida64_d1)\n",
    "rjf_ok['florida'] = florida64_d2.iloc[:,1]\n",
    "print(\"florida64: \",(florida64_d2.iloc[:,1]*rjf_ok['move']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMade64:  1026944\n",
      "MinMade96:  71721\n"
     ]
    }
   ],
   "source": [
    "MinMade64_d1=rjf_ok['upc'].isin(MinMade64['upc'])\n",
    "MinMade64_d2=pd.get_dummies(MinMade64_d1)\n",
    "MinMade96_d1=rjf_ok['upc'].isin(MinMade96['upc'])\n",
    "MinMade96_d2=pd.get_dummies(MinMade96_d1)\n",
    "rjf_ok['MinMade'] = MinMade64_d2.iloc[:,1]+MinMade96_d2.iloc[:,1]\n",
    "print(\"MinMade64: \",(MinMade64_d2.iloc[:,1]*rjf_ok['move']).sum())\n",
    "print(\"MinMade96: \",(MinMade96_d2.iloc[:,1]*rjf_ok['move']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HH64:  1352914\n",
      "HH128(96):  285351\n"
     ]
    }
   ],
   "source": [
    "HH64_d1=rjf_ok['upc'].isin(HH64['upc'])\n",
    "HH64_d2=pd.get_dummies(HH64_d1)\n",
    "HH128_d1=rjf_ok['upc'].isin(HH128['upc']) # I used 128 OZ because it is the only different size from 64. no Dom in Dataset\n",
    "HH128_d2=pd.get_dummies(HH128_d1)\n",
    "rjf_ok['HH'] = HH64_d2.iloc[:,1]+HH128_d2.iloc[:,1]\n",
    "print(\"HH64: \",(HH64_d2.iloc[:,1]*rjf_ok['move']).sum())\n",
    "print(\"HH128(96): \",(HH128_d2.iloc[:,1]*rjf_ok['move']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TropPr64:  639779\n",
      "TropPr96:  176850\n"
     ]
    }
   ],
   "source": [
    "TropPr64_d1=rjf_ok['upc'].isin(TropPr64['upc'])\n",
    "TropPr64_d2=pd.get_dummies(TropPr64_d1)\n",
    "TropPr96_d1=rjf_ok['upc'].isin([TropPr96['upc']])\n",
    "TropPr96_d2=pd.get_dummies(TropPr96_d1)\n",
    "rjf_ok['Tropic'] = TropPr64_d2.iloc[:,1]+TropPr96_d2.iloc[:,1]\n",
    "print(\"TropPr64: \",(TropPr64_d2.iloc[:,1]*rjf_ok['move']).sum())\n",
    "print(\"TropPr96: \",(TropPr96_d2.iloc[:,1]*rjf_ok['move']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TropSB64:  741646\n"
     ]
    }
   ],
   "source": [
    "TropSB64_d1=rjf_ok['upc'].isin(TropSB64['upc'])\n",
    "TropSB64_d2=pd.get_dummies(TropSB64_d1)\n",
    "rjf_ok['TropicSB'] = TropSB64_d2.iloc[:,1]\n",
    "print(\"TropSB64: \",(TropSB64_d2.iloc[:,1]*rjf_ok['move']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok['64 OZ']=florida64_d2.iloc[:,1]+MinMade64_d2.iloc[:,1]+HH64_d2.iloc[:,1]+TropPr64_d2.iloc[:,1]+TropSB64_d2.iloc[:,1]\n",
    "rjf_ok['96 OZ']=MinMade96_d2.iloc[:,1]+HH128_d2.iloc[:,1]+TropPr96_d2.iloc[:,1]\n",
    "rjf_ok['nobrand']=1-rjf_ok['64 OZ']-rjf_ok['96 OZ'] #nobrand=1 other brands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rjf_ok.iloc[:5,15:]\n",
    "#rjf_ok=rjf_ok.drop(columns=['Domm', ' 64'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rjf_ok = rjf_ok.loc[lambda rjnb: rjf_ok.nobrand==0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida=rjf_ok.move*rjf_ok.florida\n",
    "MinMade=rjf_ok.move*rjf_ok.MinMade\n",
    "HH=rjf_ok.move*rjf_ok.HH\n",
    "Tropic=rjf_ok.move*rjf_ok.Tropic\n",
    "TropicSB=rjf_ok.move*rjf_ok.TropicSB\n",
    "total=florida.sum()+MinMade.sum()+HH.sum()+Tropic.sum()+TropicSB.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029229093259623057\n",
      "0.24831225011470145\n",
      "0.3702687065066798\n",
      "0.1845685304427815\n",
      "0.1676214196762142\n"
     ]
    }
   ],
   "source": [
    "print(florida.sum()/total)\n",
    "print(MinMade.sum()/total)\n",
    "print(HH.sum()/total)\n",
    "print(Tropic.sum()/total)\n",
    "print(TropicSB.sum()/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Prices: F64:  2.3090356852890004 M64 1.798598842780132 M96 3.4540322917973816 H64 1.3399150130754798 H96 3.1722692753836506 T64 2.3887041775363054 T96 4.165218659881255 TSB64 1.6379981824212628\n",
      "Avg. Costs: F64:  1.5746899974869515 M64 1.5280160532998879 M96 2.537460605526973 H64 0.8633268559065839 H96 2.029978377016445 T64 1.7292947001652132 T96 3.068523378360192 TSB64 1.3871188670093277\n"
     ]
    }
   ],
   "source": [
    "#Price, and cost, Descriptive Statistics\n",
    "\n",
    "AvgP_f64 = np.sum(rjf_ok['florida']*rjf_ok['64 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['florida']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "AvgC_f64 = np.sum(rjf_ok['florida']*rjf_ok['64 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['florida']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_m64 = np.sum(rjf_ok['MinMade']*rjf_ok['64 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['MinMade']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "AvgC_m64 = np.sum(rjf_ok['MinMade']*rjf_ok['64 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['MinMade']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_m96 = np.sum(rjf_ok['MinMade']*rjf_ok['96 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['MinMade']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "AvgC_m96 = np.sum(rjf_ok['MinMade']*rjf_ok['96 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['MinMade']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_h64 = np.sum(rjf_ok['HH']*rjf_ok['64 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['HH']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "AvgC_h64 = np.sum(rjf_ok['HH']*rjf_ok['64 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['HH']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_h96 = np.sum(rjf_ok['HH']*rjf_ok['96 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['HH']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "AvgC_h96 = np.sum(rjf_ok['HH']*rjf_ok['96 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['HH']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_t64 = np.sum(rjf_ok['Tropic']*rjf_ok['64 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['Tropic']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "AvgC_t64 = np.sum(rjf_ok['Tropic']*rjf_ok['64 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['Tropic']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_t96 = np.sum(rjf_ok['Tropic']*rjf_ok['96 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['Tropic']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "AvgC_t96 = np.sum(rjf_ok['Tropic']*rjf_ok['96 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['Tropic']*rjf_ok['96 OZ']*rjf_ok['move'])\n",
    "\n",
    "AvgP_tsb64 = np.sum(rjf_ok['TropicSB']*rjf_ok['64 OZ']*rjf_ok['price']*rjf_ok['move'])/np.sum(rjf_ok['TropicSB']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "AvgC_tsb64 = np.sum(rjf_ok['TropicSB']*rjf_ok['64 OZ']*(rjf_ok['price']*(1-rjf_ok['profit']/100))*rjf_ok['move'])/np.sum(rjf_ok['TropicSB']*rjf_ok['64 OZ']*rjf_ok['move'])\n",
    "\n",
    "print(\"Avg. Prices: F64: \", AvgP_f64, \"M64\",AvgP_m64 , \"M96\", AvgP_m96, \"H64\", AvgP_h64, \"H96\", AvgP_h96, \"T64\", AvgP_t64, \"T96\", AvgP_t96, \"TSB64\", AvgP_tsb64)\n",
    "print(\"Avg. Costs: F64: \", AvgC_f64, \"M64\",AvgC_m64 , \"M96\", AvgC_m96, \"H64\", AvgC_h64, \"H96\", AvgC_h96, \"T64\", AvgC_t64, \"T96\", AvgC_t96, \"TSB64\", AvgC_tsb64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InstVar(price, instruments):\n",
    "    first_stage = sm.OLS(price,instruments).fit()\n",
    "    coeffs = first_stage.params\n",
    "    price_est = instruments@coeffs\n",
    "    price_estf = np.reshape(price_est,(price_est.size,1))\n",
    "    return price_estf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Variables to be estimated:\n",
    "    \n",
    "alpha => alpha_j (with j for each brand), mean intrinsic utility across consumers for brand and size x\n",
    "\n",
    "sigma => sigma_income, sigma_age, sigma_ethnic, sigma_hval, sigma_shopindx, sigma_edlpd: deviations \n",
    "from the mean due to demographic variables (common values across stores)\n",
    "\n",
    "beta => beta_promo, beta_size: mean coefficients for observed attributes\n",
    "    \n",
    "lambda_p&s => lambda_promo, lambda_size: deviation coefficients for for observed attributes\n",
    "    \n",
    "theta and gamma => theta_price, gamma_income, gamma_age, gamma_ethnic, gamma_hval, gamma_shopindx, gamma_edlpd: coefficients for price\n",
    "    \n",
    "lambda_price => lambda_price: coefficient for the deviation of price\n",
    "\n",
    "l_matrix => l1_j, l2_j = coefficients of the latent attributes for each brand \n",
    "\n",
    "draws are relative to the standard deviations coefficients\n",
    "\"\"\"\n",
    "print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"main equations:\n",
    "    \n",
    "delta(alpha, beta, sigma, gamma, promo and size, demog_vars, brand_dummies, price, xi): this function calculates the mean utility \n",
    "for each brand and store. \n",
    "\n",
    "delta_jts = brand_dummies_ts@alpha_j+ promo&size@beta + demog_vars_s@sigma \\\n",
    "            - (theta+demog_vars_s@gamma)*price_jts + xi // vec. of obsx1\n",
    "\n",
    "mu(promo&size, price, lambda_p&s, lambda_price, l_matrix, simulation draws): this function calculates the deviations from \n",
    "the mean, using independent draws.\"\"\"\n",
    "print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_fun (alpha, beta, sigma, gamma, theta, xi, data_promo_size, data_demog, brand_dummies, price, store_week):\n",
    "    a = np.reshape(alpha,(alpha.size,1))\n",
    "    b = np.reshape(beta,(beta.size,1))\n",
    "    s = np.reshape(sigma,(sigma.size,1))\n",
    "    g = np.reshape(gamma,(gamma.size,1))\n",
    "    ps = data_promo_size\n",
    "    dd = data_demog\n",
    "    bd = brand_dummies\n",
    "    p = price\n",
    "    mkt = np.reshape(store_week,(store_week.size,1))\n",
    "    \n",
    "    delta_mat = np.zeros((mkt.shape[0], 2))\n",
    "    delta_mat[:,0] = mkt[:,0]\n",
    "    trd = dd@s + bd@a +ps@b + (theta+dd@g)*p    #+ xi[:,0] # obs x 2 matrix, 2nd column vector of deltas\n",
    "    delta_mat[:,1] = trd[:,0]\n",
    "    return delta_mat\n",
    "\n",
    "def mu_fun(data_promo_size, price, brand_dummies, L_matrix, lambda_x,lambda_price, sim_beta, sim_theta, sim_w):\n",
    "    \n",
    "    ps = np.reshape(data_promo_size,(data_promo_size.shape[0],data_promo_size.shape[1]))\n",
    "    p = np.reshape(price,(price.size,1))\n",
    "    bd = brand_dummies\n",
    "\n",
    "    lambda_x = np.reshape(lambda_x,(lambda_x.size,1))\n",
    "    L_matrix = L_matrix\n",
    "    \n",
    "    sim_beta = sim_beta\n",
    "    sim_theta = np.reshape(sim_theta,(sim_theta.size,1))\n",
    "    sim_w = sim_w\n",
    "    \n",
    "    sim_mat = np.hstack((sim_beta*lambda_x.T, lambda_price*sim_theta,sim_w@L_matrix.T)) # S x (J+3) matrix\n",
    "    param_mat = np.hstack((ps,price,brand_dummies))  # obs x (J+3) matrix\n",
    "    \n",
    "    mu_mat = param_mat@sim_mat.T #obsxS\n",
    "    return mu_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction mapping\n",
    "\n",
    "def est_ms_cm(delta1, theta2, data, simP):\n",
    "    sim_beta, sim_theta, sim_w = simP\n",
    "    data_promo_size, data_demog, brand_dummies, price, store_week, share = data\n",
    "    L_matrix, lambda_x,lambda_price = theta2\n",
    "\n",
    "    d=delta1\n",
    "    mu = mu_fun(data_promo_size, price, brand_dummies,L_matrix, lambda_x,lambda_price,sim_beta, sim_theta, sim_w) # obs x S\n",
    "\n",
    "    delta = d[:,1]\n",
    "    delta = np.reshape(np.asarray(delta),(price.size,1))\n",
    "    share = np.reshape(np.asarray(share),(share.size,1))\n",
    "    delta = np.exp(delta)\n",
    "    mu = np.exp(mu)\n",
    "    market = np.reshape(store_week,(store_week.size,1))\n",
    "\n",
    "    share_mat = delta*mu\n",
    "    share_mat = np.hstack((market,share_mat))\n",
    "    share_mat2 = pd.DataFrame((share_mat))\n",
    "    \n",
    "    tot_share_mat = share_mat2.groupby(share_mat2.iloc[:,0]).sum()\n",
    "    tot_share_mat = tot_share_mat + 1\n",
    "    \n",
    "    share_mat2=share_mat2.rename(columns={0:'market'})\n",
    "    share_mat2.sort_values(by=['market'])\n",
    "    \n",
    "    r2=share_mat2.iloc[0,0]\n",
    "    a=(tot_share_mat.loc[r2,1:]).values.reshape(1,30)\n",
    "    i=0\n",
    "    for i in range(share_mat2.shape[0]):\n",
    "        r=share_mat2.iloc[i,0]\n",
    "        if r==r2:\n",
    "            share_mat2.iloc[i,1:]=(share_mat2.iloc[i,1:]).values.reshape(1,30)/a #tot_share_mat.loc[r,:]\n",
    "        else:\n",
    "            r2=share_mat2.iloc[i,0]\n",
    "            a=(tot_share_mat.loc[r2,1:]).values.reshape(1,30)\n",
    "            share_mat2.iloc[i,1:]=(share_mat2.iloc[i,1:]).values.reshape(1,30)/a\n",
    "    \n",
    "    ns = mu.shape[1]\n",
    "    est_shares_vec = np.zeros((d.shape[0],1))\n",
    "    est_shares_vec[:,0] = (share_mat2.iloc[:,1:].sum(axis=1)).apply(lambda x: x*(1/ns))\n",
    "    new_delta_3 = d[:,1] + np.log(share[:,0]) - np.log(est_shares_vec[:,0])\n",
    "    d[:,1] = new_delta_3\n",
    "    new_delta = d\n",
    "    return new_delta, est_shares_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates the new deltas for the iteration.\n",
    "\n",
    "def delta_eq(d_in,theta2, data, simP):\n",
    "    data_promo_size, data_demog, brand_dummies, price, store_week, share = data\n",
    " \n",
    "    delta_new, estim_shares_new = est_ms_cm(d_in, theta2, data, simP) # estimated shares are not used in this cell.\n",
    "\n",
    "    diff_sh = abs(np.log(share) - np.log(estim_shares_new))\n",
    "    epsilon = 1e-8\n",
    "    i=0\n",
    "    while diff_sh.all() >= epsilon:\n",
    "        delta_ant=delta_new\n",
    "        delta_new, est_shares_new = est_ms_cm(delta_ant, theta2, data, simP)\n",
    "        diff_sh = abs(np.log(share) - np.log(est_shares_new))\n",
    "        print(diff_sh.max())\n",
    "        i+=1\n",
    "\n",
    "    delta_eq = delta_new\n",
    "    \n",
    "    return delta_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function calculates the error vector (xi_jt)\n",
    "\n",
    "def errorvec(delta_inic, data, theta1, theta2, xi, simP):\n",
    "    \n",
    "    alpha, beta, sigma, gamma, theta = theta1\n",
    "    data_promo_size, data_demog, brand_dummies, price, store_week, share = data\n",
    "    delta_equiv = delta_eq(delta_inic, theta2,data, simP)\n",
    "\n",
    "    delta_mod = delta_fun(alpha, beta, sigma, gamma, theta, xi, data_promo_size, data_demog, brand_dummies, price, store_week)\n",
    "\n",
    "    error_vec = delta_equiv[:,1] - delta_mod[:,1]\n",
    "    \n",
    "    return error_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logs(market, share_obs):\n",
    "    storeweek = np.array(market)\n",
    "    share = np.array(share_obs)\n",
    "    ts=np.zeros((share.shape[0],1))\n",
    "    share2=np.hstack((storeweek,share,ts))\n",
    "    share2=pd.DataFrame((share2))\n",
    "    tot_shares_real=share2.groupby(share2.iloc[:,0]).sum()\n",
    "    i=0\n",
    "    for i in range(share.shape[0]):\n",
    "        r=share2.iloc[i,0]\n",
    "        tots=tot_shares_real.loc[r,:]\n",
    "        share2.iloc[i,2]=1-tots[1]\n",
    "        i+=1\n",
    "    logs=np.asarray(np.log(share2.iloc[:,1])-np.log(share2.iloc[:,2]))\n",
    "    logs=np.reshape(logs, (logs.size,1))\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramsnohet(datax, theta1):\n",
    "    alpha, beta, sigma, gamma, theta = theta1\n",
    "    data_promo_size, data_demog, brand_dummies, price, store_week, share = datax\n",
    "    \n",
    "    a = np.reshape(alpha,(alpha.size,1))\n",
    "    b = np.reshape(beta,(beta.size,1))\n",
    "    s = np.reshape(sigma,(sigma.size,1))\n",
    "    g = np.reshape(gamma,(gamma.size,1))\n",
    "    ps = data_promo_size\n",
    "    dd = data_demog\n",
    "    bd = brand_dummies\n",
    "    p = price\n",
    "    mkt = np.reshape(store_week,(store_week.size,1))\n",
    "    \n",
    "    Y = logs(mkt, share)\n",
    "    X=np.hstack((ps, dd, p, bd, dd*p))\n",
    "    X=pd.DataFrame(X)\n",
    "    X.columns=['promo', '64 OZ', 'income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist', 'price_e',\\\n",
    "              'florida','MinMade','HH','Tropic','TropicSB', 'inc*p', 'AGE*p', 'eth*p', 'hval*p', 'shop*p', 'EDLP*p']\n",
    "    \n",
    "    trd = dd@s + bd@a +ps@b + (theta+dd@g)*p\n",
    "    \n",
    "    par_nohet = sm.OLS(Y,X).fit()\n",
    "    return trd.shape, par_nohet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMM code\n",
    "def GMM_criterion(params, *args):\n",
    "    theta1, del_in, data, xi, simP, instruments = args\n",
    "    a1,a2,a3,a4,a5,b1,b2,s1,s2,s3,s4,s5,s6,g1,g2,g3,g4,g5,g6, theta,\\\n",
    "    L11,L21,L22,L31,L32,L41,L42,L51,L52,lx1,lx2,lambda_price = params\n",
    "    data_promo_size, data_demog, brand_dummies, price, store_week, share = data\n",
    "    \n",
    "    alpha=np.array([a1,a2,a3,a4,a5])\n",
    "    beta=np.array([b1,b2])\n",
    "    gamma = np.array([g1,g2,g3,g4,g5,g6])\n",
    "    sigma = np.array([s1,s2,s3,s4,s5,s6])\n",
    "    L_matrix=np.array([[L11,0],[L21,L22],[L31,L32],[L41,L42],[L51,L52]])\n",
    "    lambda_x = np.array([lx1,lx2])\n",
    "    \n",
    "    theta1=(alpha, beta, sigma, gamma, theta)\n",
    "    theta2=(L_matrix, lambda_x, lambda_price)\n",
    "    Z=instruments\n",
    "    mat_inv = lin.inv(Z.T@Z)\n",
    "    error_vec = errorvec(del_in, data, theta1, theta2, xi, simP)\n",
    "    GMM = error_vec.T@Z@mat_inv@Z.T@error_vec\n",
    "    print(\"GMM: \",GMM)\n",
    "    return GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of parameters, variables and draws:\n",
    "\n",
    "#### Case 2: Refrigerated Orange Juice\n",
    "\n",
    "- Brands: florida, MinuteMade, HH, Tropicana Premium, Tropicana SB (Dominick's own brand information not available)\n",
    "- Sizes: 64 OZ and 96 OZ\n",
    "\n",
    "##### Variables:\n",
    "\n",
    "- price: rows: # obs, columns: weekly price per product per store\n",
    "- data_demog: rows: # obs, columns: income, age, ethnic, hval, shopindx, edlpd\n",
    "- brand_dummies: rows: # obs, columns: 5 columns of dummies for florida, MinuteMade, HH, Tropicana Premium, Tropicana SB respectively\n",
    "- data_promo_size: rows: # obs, columns: 2 columns of dummies for promo (1 if the price includes promo) and size (64 OZ = 1)\n",
    "- storeweek: rows: # obs, columns: ID for each market (built from original columns (store x 1,000) + week)\n",
    "- share: rows: # obs, columns: absolute share (also considering outside opt) for each product in each market.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "- alpha: rows: 5, columns: 1 => alpha_florida, alpha_MinMade, alpha_HH, alpha_TropicPr, alpha_TropicSB\n",
    "- beta: rows: 2, columns: 1 => beta_promo, beta_size\n",
    "- sigma: rows: 6, columns: 1 => sigma_income, sigma_age, sigma_ethnic, sigma_hval, sigma_shopindx, sigma_edlpd\n",
    "- gamma: rows: 6, columns: 1 => gamma_income, gamma_age, gamma_ethnic, gamma_hval, gamma_shopindx, gamma_edlpd\n",
    "- theta: 1 parameter, scalar\n",
    "- L_matrix: rows: 5, columns: 2 => [[L1_florida, L2_florida],[L1_MinMade, L2_MinMade], [L1_HH, L2_HH], [L1_TropPr, L2_TropPr], [L1_TropSB, L2_TropSB]].\n",
    "- lambda_x: rows: 2, columns: 1 => lambda_promo, lambda_size\n",
    "- lambda_price: 1 parameter, scalar\n",
    "\n",
    "##### Draws:\n",
    "\n",
    "Normal Standard draws.\n",
    "\n",
    "- sim_beta: rows: #Draws, columns: 2 => sim_beta_promo, sim_beta_size. Draws for the standard deviation of promo and size \n",
    "- sim_theta: rows: #Draws, columns: 1 => sim_theta. Draws for the theta parameter relative to price\n",
    "- sim_w: rows: #Draws, columns: 2 => sim_w1, sim_w2. Draws for the w vector used to calculate the Sigma matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2) (30, 1) (30, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating uniform and standard normal draws\n",
    "\n",
    "sim_draws_beta = 30\n",
    "sim_draws_theta = 30\n",
    "sim_draws_w = 30\n",
    "np.random.seed(1979)\n",
    "\n",
    "uniform_beta = sts.uniform.rvs(0, 1, size=(sim_draws_beta,2))\n",
    "normal_beta_draws = sts.norm.ppf(uniform_beta, loc=0, scale=1)\n",
    "\n",
    "uniform_theta = sts.uniform.rvs(0, 1, size=(sim_draws_theta, 1))\n",
    "normal_theta_draws = sts.norm.ppf(uniform_theta, loc=0, scale=1)\n",
    "\n",
    "uniform_w = sts.uniform.rvs(0, 1, size=(sim_draws_w, 2))\n",
    "normal_w_draws = sts.norm.ppf(uniform_w, loc=0, scale=1)\n",
    "\n",
    "print(normal_beta_draws.shape, normal_theta_draws.shape, normal_w_draws.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_ini(market, share_obs):\n",
    "    storeweek = np.array(market)\n",
    "    share = np.array(share_obs)\n",
    "    ts=np.zeros((share.shape[0],1))\n",
    "    share2=np.hstack((storeweek,share,ts))\n",
    "    share2=pd.DataFrame((share2))\n",
    "    tot_shares_real=share2.groupby(share2.iloc[:,0]).sum()\n",
    "    i=0\n",
    "    for i in range(share.shape[0]):\n",
    "        r=share2.iloc[i,0]\n",
    "        tots=tot_shares_real.loc[r,:]\n",
    "        share2.iloc[i,2]=1-tots[1]\n",
    "        i+=1\n",
    "    logs=np.asarray(np.log(share2.iloc[:,1])-np.log(share2.iloc[:,2]))\n",
    "    logs=np.reshape(logs, (logs.size,1))\n",
    "    delta_in=np.hstack((storeweek,logs))\n",
    "    return delta_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data, grouping it by store-week\n",
    "\n",
    "demog = np.array(rjf_ok[['income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist']])\n",
    "brands = np.array(rjf_ok[['florida','MinMade','HH','Tropic','TropicSB']])\n",
    "price = np.array(np.log(rjf_ok[['price']]))\n",
    "wholeprice = np.log(np.array(rjf_ok[['price']])*(1-np.array(rjf_ok[['profit']])/100))\n",
    "promo=np.reshape(rjf_ok[['promo']],(rjf_ok[['promo']].shape[0],1))\n",
    "instr=np.hstack((promo,demog, wholeprice, brands))\n",
    "price_est=InstVar(price,instr)\n",
    "\n",
    "datapack_GMM = np.hstack((price_est, wholeprice, rjf_ok[['promo', '64 OZ', '96 OZ', 'move','totcount', 'income', 'AGE60',\\\n",
    "                                                          'ethnic', 'hvalmean','shopindx','sstrdist', 'florida','MinMade','HH'\\\n",
    "                                                          ,'Tropic','TropicSB', 'price', 'store-week', 'share', 'store', 'zone', 'week']]))\n",
    "\n",
    "datapack_GMM=pd.DataFrame(datapack_GMM)\n",
    "datapack_GMM.columns = ['Price_est', 'wholeprice', 'promo', '64 OZ', '96 OZ', 'move','totcount', 'income', 'AGE60',\\\n",
    "                        'ethnic', 'hvalmean','shopindx','sstrdist', 'florida','MinMade','HH','Tropic',\\\n",
    "                        'TropicSB', 'price', 'store-week', 'share', 'store', 'zone', 'week']\n",
    "datapack_GMM['64_OZ(2)']=datapack_GMM[['64 OZ']]\n",
    "datapack_GMM['Price_est']=datapack_GMM['Price_est']*datapack_GMM['move']\n",
    "datapack_GMM['wholeprice']=datapack_GMM['wholeprice']*datapack_GMM['move']\n",
    "datapack_GMM = datapack_GMM.groupby(['store-week', 'florida', 'MinMade', 'HH', 'Tropic', 'TropicSB', '64 OZ'], as_index=False).sum()\n",
    "\n",
    "datapack_GMM['Price_est'] =datapack_GMM['Price_est']/(datapack_GMM['move']) \n",
    "datapack_GMM['wholeprice'] =datapack_GMM['wholeprice']/(datapack_GMM['move']) \n",
    "datapack_GMM['totcount'] =datapack_GMM['totcount']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['income'] =datapack_GMM['income']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['AGE60'] =datapack_GMM['AGE60']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['ethnic'] =datapack_GMM['ethnic']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['hvalmean'] =datapack_GMM['hvalmean']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['shopindx'] =datapack_GMM['shopindx']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['sstrdist'] =datapack_GMM['sstrdist']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['price'] =datapack_GMM['price']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['store'] =datapack_GMM['store']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['zone'] =datapack_GMM['zone']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "datapack_GMM['week'] =datapack_GMM['week']/(datapack_GMM['96 OZ']+datapack_GMM['64_OZ(2)']) \n",
    "\n",
    "i=0\n",
    "for i in range(datapack_GMM.shape[0]):\n",
    "    if datapack_GMM.loc[i,'promo']>0:\n",
    "        datapack_GMM.loc[i,'promo'] = 1\n",
    "    else:\n",
    "        pass\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "promosize = np.array(datapack_GMM[['promo', '64 OZ']])\n",
    "demog = np.array(datapack_GMM[['income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist']])\n",
    "brands = np.array(datapack_GMM[['florida','MinMade','HH','Tropic','TropicSB']])\n",
    "price = np.array(datapack_GMM[['price']])#.astype(np.float16)\n",
    "storeweek = np.array(datapack_GMM[['store-week']])\n",
    "share = np.array(datapack_GMM[['share']])\n",
    "price_est=np.array(datapack_GMM[['Price_est']])\n",
    "promo = np.array(datapack_GMM[['promo']])\n",
    "wholeprice = np.array(datapack_GMM[['wholeprice']])\n",
    "\n",
    "delta_in=delta_ini(storeweek,share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (promosize, demog, brands, price_est, storeweek, share)\n",
    "\n",
    "alpha=np.array([0,0,0,0,0])\n",
    "beta=np.array([0,0])\n",
    "gamma = np.array([0,0,0,0,0,0])\n",
    "sigma = np.array([0,0,0,0,0,0])\n",
    "theta = 0\n",
    "\n",
    "theta1=(alpha, beta, sigma, gamma, theta)\n",
    "\n",
    "results_nohet=paramsnohet(data, theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29893, 1), <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                             OLS Regression Results                            \n",
       " ==============================================================================\n",
       " Dep. Variable:                      y   R-squared:                       0.524\n",
       " Model:                            OLS   Adj. R-squared:                  0.524\n",
       " Method:                 Least Squares   F-statistic:                     1731.\n",
       " Date:                Fri, 22 Mar 2019   Prob (F-statistic):               0.00\n",
       " Time:                        09:17:52   Log-Likelihood:                -36183.\n",
       " No. Observations:               29893   AIC:                         7.241e+04\n",
       " Df Residuals:                   29873   BIC:                         7.257e+04\n",
       " Df Model:                          19                                         \n",
       " Covariance Type:            nonrobust                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " promo          0.7175      0.012     60.083      0.000       0.694       0.741\n",
       " 64 OZ          2.0022      0.032     62.330      0.000       1.939       2.065\n",
       " income        -0.0480      0.163     -0.294      0.768      -0.368       0.272\n",
       " AGE60          2.9029      0.252     11.539      0.000       2.410       3.396\n",
       " ethnic         0.1446      0.131      1.101      0.271      -0.113       0.402\n",
       " hvalmean      -0.0022      0.001     -3.525      0.000      -0.003      -0.001\n",
       " shopindx      -0.6129      0.154     -3.988      0.000      -0.914      -0.312\n",
       " sstrdist      -0.0094      0.005     -1.880      0.060      -0.019       0.000\n",
       " price_e       -4.7870      1.626     -2.944      0.003      -7.975      -1.599\n",
       " florida       -8.9642      1.589     -5.643      0.000     -12.078      -5.851\n",
       " MinMade       -7.3520      1.588     -4.630      0.000     -10.464      -4.240\n",
       " HH            -6.3738      1.587     -4.015      0.000      -9.485      -3.262\n",
       " Tropic        -7.2199      1.589     -4.545      0.000     -10.334      -4.106\n",
       " TropicSB      -7.6181      1.588     -4.797      0.000     -10.731      -4.505\n",
       " inc*p          0.5275      0.167      3.152      0.002       0.200       0.856\n",
       " AGE*p         -2.7953      0.259    -10.812      0.000      -3.302      -2.288\n",
       " eth*p          0.0173      0.134      0.130      0.897      -0.245       0.280\n",
       " hval*p         0.0041      0.001      6.253      0.000       0.003       0.005\n",
       " shop*p         0.4229      0.159      2.659      0.008       0.111       0.735\n",
       " EDLP*p        -0.0087      0.005     -1.715      0.086      -0.019       0.001\n",
       " ==============================================================================\n",
       " Omnibus:                     1910.663   Durbin-Watson:                   1.944\n",
       " Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5226.830\n",
       " Skew:                           0.353   Prob(JB):                         0.00\n",
       " Kurtosis:                       4.923   Cond. No.                     1.73e+05\n",
       " ==============================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " [2] The condition number is large, 1.73e+05. This might indicate that there are\n",
       " strong multicollinearity or other numerical problems.\n",
       " \"\"\")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nohet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=-8.9642\n",
    "a2=-7.3520\n",
    "a3=-6.3738\n",
    "a4=-7.2199\n",
    "a5=-7.6181\n",
    "b1=0.7175\n",
    "b2=2.0022\n",
    "s1=-0.0480\n",
    "s2=2.9029\n",
    "s3=0.1446\n",
    "s4=-0.0022\n",
    "s5=-0.6129\n",
    "s6=-0.0094\n",
    "g1=0.5275\n",
    "g2=-2.7953\n",
    "g3=0.0173\n",
    "g4=0.0041\n",
    "g5= 0.4229\n",
    "g6=-0.0087\n",
    "\n",
    "theta = -4.7870\n",
    "\n",
    "#L12 arbitrarily set to zero\n",
    "(L11,L21,L22,L31,L32,L41,L42,L51,L52,lx1,lx2,lambda_price)=np.array([0.67759551, 1.03441918, 0.65452123, \\\n",
    "                                                                     0.65452234, 1.02568196, 0.65452186, 0.65452142, \\\n",
    "                                                                     0.65452133, 0.65452136, 0.6545626,  0.65464387, \\\n",
    "                                                                     0.65452742])\n",
    "\n",
    "alpha=np.array([a1,a2,a3,a4,a5])\n",
    "beta=np.array([b1,b2])\n",
    "gamma = np.array([g1,g2,g3,g4,g5,g6])\n",
    "sigma = np.array([s1,s2,s3,s4,s5,s6])\n",
    "\n",
    "theta1=(alpha, beta, sigma, gamma, theta)\n",
    "\n",
    "\n",
    "simP = (normal_beta_draws, normal_theta_draws, normal_w_draws)\n",
    "\n",
    "params = np.array([a1,a2,a3,a4,a5,b1,b2,s1,s2,s3,s4,s5,s6,g1,g2,g3,g4,g5,g6,theta,\\\n",
    "                   L11,L21,L22,L31,L32,L41,L42,L51,L52,lx1,lx2,lambda_price])\n",
    "\n",
    "xi = np.zeros((datapack_GMM.shape[0],1))\n",
    "\n",
    "instruments=np.hstack((promo,demog, wholeprice, brands))\n",
    "\n",
    "args = (theta1, delta_in, data, xi, simP, instruments)\n",
    "Bounds = ((None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None),\\\n",
    "          (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None),\\\n",
    "          (None, None), (None, None), (None, None), (None, None), (None, None), (None, None),\\\n",
    "          (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None),\\\n",
    "          (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None), (1e-10, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7912618055504481e-09\n",
      "6.446443379104494e-10\n",
      "GMM:  14164.046503771799\n",
      "GMM:  14164.046502127729\n",
      "GMM:  14164.04658211123\n",
      "GMM:  14164.046665599062\n",
      "GMM:  14164.046646394618\n",
      "GMM:  14164.04661071721\n",
      "GMM:  14164.046581011598\n",
      "GMM:  14164.046804848913\n",
      "GMM:  14164.046937872037\n",
      "GMM:  14164.052629255988\n",
      "GMM:  14164.046601885904\n",
      "GMM:  14164.04659454363\n",
      "GMM:  14164.129873966433\n",
      "GMM:  14164.046931300585\n",
      "GMM:  14164.049555981608\n",
      "GMM:  14164.051525220919\n",
      "GMM:  14164.046584049318\n",
      "GMM:  14164.04657817172\n",
      "GMM:  14164.115105820223\n",
      "GMM:  14164.046852867457\n",
      "GMM:  14164.049037320503\n",
      "GMM:  14164.046975184952\n",
      "GMM:  14164.04652717332\n",
      "1.400978888455029e-09\n",
      "GMM:  14164.046597268789\n",
      "1.3825136591094633e-09\n",
      "GMM:  14164.04655642519\n",
      "1.2490382061969285e-09\n",
      "3.5539082787749976e-10\n",
      "GMM:  14164.046569554608\n",
      "1.0833773878005104e-09\n",
      "5.897611288219196e-10\n",
      "GMM:  14164.046575243574\n",
      "1.4576135853872074e-09\n",
      "4.850042589765735e-10\n",
      "2.642768226479575e-10\n",
      "GMM:  14164.04654017309\n",
      "GMM:  14164.046526270275\n",
      "GMM:  14164.046527618415\n",
      "9.172076431696041e-10\n",
      "GMM:  14164.046523809748\n",
      "2.4422126543299782e-09\n",
      "9.126328581743337e-10\n",
      "GMM:  14164.046699475268\n",
      "2.8160580534120072e-09\n",
      "8.172862386857105e-10\n",
      "2.848736802008034e-10\n",
      "GMM:  14164.046888271354\n",
      "2.75521339077045e-09\n",
      "8.414260399547402e-10\n",
      "GMM:  14164.046586846369\n",
      "0.08212209026856865\n",
      "0.01886582573094686\n",
      "0.00616108881602262\n",
      "0.0021514326161893305\n",
      "GMM:  6.802188206607281e+22\n",
      "0.17080385294171752\n",
      "0.05794617387769918\n",
      "0.02289217421878753\n",
      "0.009551012548216775\n",
      "0.00396138984587413\n",
      "GMM:  6.802188163599408e+20\n",
      "0.028083787400809967\n",
      "0.009403268904070394\n",
      "0.0037756120995231512\n",
      "0.001647175935661771\n",
      "0.0007213710532045781\n",
      "GMM:  6.802187688318368e+18\n",
      "0.002861583543992019\n",
      "0.0009733401496916372\n",
      "0.0003952099268129672\n",
      "0.00017394944454185435\n",
      "7.655596515476759e-05\n",
      "GMM:  6.802182931094442e+16\n",
      "0.00028682173843375125\n",
      "9.767057897924758e-05\n",
      "3.9763822084815104e-05\n",
      "1.7508917491859677e-05\n",
      "7.709504299846515e-06\n",
      "GMM:  680213535902181.8\n",
      "2.8688713003877098e-05\n",
      "9.770463549330088e-06\n",
      "3.979183810898235e-06\n",
      "1.7521961606092873e-06\n",
      "7.715622487580731e-07\n",
      "GMM:  6801659650743.952\n",
      "2.868936593625193e-06\n",
      "9.77080580888412e-07\n",
      "3.979491429717541e-07\n",
      "1.752338691929367e-07\n",
      "GMM:  67969038297.483696\n",
      "2.8930404205596005e-07\n",
      "1.0346039047703925e-07\n",
      "4.348249227348333e-08\n",
      "1.9147192276136593e-08\n",
      "GMM:  674947182.1428024\n",
      "2.894943751385881e-08\n",
      "1.0402112060603486e-08\n",
      "4.4093031448255715e-09\n",
      "GMM:  6287771.903561968\n",
      "3.0995703781400152e-09\n",
      "1.214312206343493e-09\n",
      "GMM:  29327.89266985451\n",
      "3.645030943744132e-10\n",
      "1.6060486274227515e-10\n",
      "7.508771382447321e-11\n",
      "GMM:  3895.3951455498363\n"
     ]
    }
   ],
   "source": [
    "results = opt.minimize(GMM_criterion, params, args=(args), method='SLSQP', bounds=Bounds, tol=1e-2) #options={'maxiter': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 3895.3951455498363\n",
       "     jac: array([5.36760193e+03, 1.09703755e+04, 9.68158704e+03, 7.28731677e+03,\n",
       "       5.29380688e+03, 2.03152748e+04, 2.92423055e+04, 4.11184617e+05,\n",
       "       6.69465784e+03, 6.20192615e+03, 5.59498939e+06, 2.88013029e+04,\n",
       "       2.04940665e+05, 3.37094078e+05, 5.49766479e+03, 5.10322583e+03,\n",
       "       4.60391587e+06, 2.35377448e+04, 1.70133907e+05, 3.17463329e+04,\n",
       "       1.68078113e+03, 6.38480847e+03, 3.64384094e+03, 4.52494128e+03,\n",
       "       4.90672131e+03, 2.55318103e+03, 1.62017883e+03, 1.71065100e+03,\n",
       "       1.45505566e+03, 1.32437692e+04, 2.59136600e+04, 5.68537170e+03])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 45\n",
       "     nit: 1\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-8.96420209e+00, -7.35200426e+00, -6.37380376e+00, -7.21990283e+00,\n",
       "       -7.61810206e+00,  7.17492107e-01,  2.00218864e+00, -4.81597602e-02,\n",
       "        2.90289740e+00,  1.44597590e-01, -4.37385751e-03, -6.12911190e-01,\n",
       "       -9.47962693e-03,  5.27369027e-01, -2.79530214e+00,  1.72980172e-02,\n",
       "        2.31121071e-03,  4.22890855e-01, -8.76610323e-03, -4.78701233e+00,\n",
       "        6.77595510e-01,  1.03441918e+00,  6.54521230e-01,  6.54522340e-01,\n",
       "        1.02568196e+00,  6.54521860e-01,  6.54521420e-01,  6.54521330e-01,\n",
       "        6.54521360e-01,  6.54562600e-01,  6.54643870e-01,  6.54527420e-01])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1,a2,a3,a4,a5,b1,b2,s1,s2,s3,s4,s5,s6,g1,g2,g3,g4,g5,g6,theta,L11,L21,L22,L31,L32,L41,L42,L51,L52,lx1,lx2,lambda_price = results.x\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the elasticities\n",
    "\n",
    "alpha_def=np.array([a1, a2, a3, a4, a5])\n",
    "beta_def=np.array([b1, b2])\n",
    "sigma_def=np.array([s1, s2, s3, s4, s5, s6])\n",
    "gamma_def=np.array([g1, g2, g3, g4, g5, g6])\n",
    "L_matrix_def=np.array([[L11, 0], [L21, L22],  [L31, L32],  \\\n",
    "                   [L41,  L42],  [L51, L52]])\n",
    "lambda_p_s_def=np.array([lx1, lx2])\n",
    "theta_def=theta\n",
    "lambda_price_def=lambda_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_def=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, price_est, storeweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_def=mu_fun(promosize, price_est, brands, L_matrix_def, lambda_p_s_def,lambda_price_def, normal_beta_draws, normal_theta_draws, normal_w_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the equilibrium market shares\n",
    "\n",
    "th2=(L_matrix_def, lambda_p_s_def,lambda_price_def)\n",
    "data=(promosize, demog, brands, price_est, storeweek,share)\n",
    "simpack=(normal_beta_draws, normal_theta_draws, normal_w_draws)\n",
    "d_test, est_sh_test =est_ms_cm(delta_def, th2, data, simpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price differentials [I NEED TO CREATE PRICES CHANGES FOR 64 AND 96 OZ SEPARATELY]\n",
    "h=1e-5\n",
    "P_florida64_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['florida']*datapack_GMM['64 OZ']), ndmin=2).T\n",
    "P_MinMade64_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['MinMade']*datapack_GMM['64 OZ']), ndmin=2).T\n",
    "P_HH64_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['HH']*datapack_GMM['64 OZ']), ndmin=2).T\n",
    "P_Tropic64_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['Tropic']*datapack_GMM['64 OZ']), ndmin=2).T\n",
    "P_TropicSB64_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['TropicSB']*datapack_GMM['64 OZ']), ndmin=2).T\n",
    "\n",
    "#P_florida96_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['florida']*datapack_GMM['96 OZ']), ndmin=2).T\n",
    "P_MinMade96_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['MinMade']*datapack_GMM['96 OZ']), ndmin=2).T\n",
    "P_HH96_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['HH']*datapack_GMM['96 OZ']), ndmin=2).T\n",
    "P_Tropic96_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['Tropic']*datapack_GMM['96 OZ']), ndmin=2).T\n",
    "#P_TropicSB96_diff=np.array(datapack_GMM['Price_est']*(1+h*datapack_GMM['TropicSB']*datapack_GMM['96 OZ']), ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta function with price differentials (TropicSB 96 OZ is not included in the paper)\n",
    "\n",
    "d_florida64=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_florida64_diff, storeweek)\n",
    "d_MinMade64=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_MinMade64_diff, storeweek)\n",
    "d_HH64=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_HH64_diff, storeweek)\n",
    "d_Tropic64=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_Tropic64_diff, storeweek)\n",
    "d_TropicSB64=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_TropicSB64_diff, storeweek)\n",
    "\n",
    "#d_florida96=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_florida96_diff, storeweek)\n",
    "d_MinMade96=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_MinMade96_diff, storeweek)\n",
    "d_HH96=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_HH96_diff, storeweek)\n",
    "d_Tropic96=delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi, promosize, demog, brands, P_Tropic96_diff, storeweek)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29893, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_florida64_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the estimated market shares upon a change in price\n",
    "\n",
    "data_florida64=(promosize, demog, brands,P_florida64_diff , storeweek,share)\n",
    "dt, shares_florida64=est_ms_cm(d_florida64, th2, data_florida64, simpack)\n",
    "\n",
    "data_MinMade64=(promosize, demog, brands, P_MinMade64_diff, storeweek,share)\n",
    "dc, shares_MinMade64=est_ms_cm(d_MinMade64, th2, data_MinMade64, simpack)\n",
    "\n",
    "data_HH64=(promosize, demog, brands, P_HH64_diff, storeweek,share)\n",
    "dw, shares_HH64=est_ms_cm(d_HH64, th2, data_HH64, simpack)\n",
    "\n",
    "data_Tropic64=(promosize, demog, brands, P_Tropic64_diff, storeweek,share)\n",
    "da, shares_Tropic64=est_ms_cm(d_Tropic64, th2, data_Tropic64, simpack)\n",
    "\n",
    "data_TropicSB64=(promosize, demog, brands, P_TropicSB64_diff, storeweek,share)\n",
    "ds, shares_TropicSB64=est_ms_cm(d_TropicSB64, th2, data_TropicSB64, simpack)\n",
    "\n",
    "data_MinMade96=(promosize, demog, brands, P_MinMade96_diff, storeweek,share)\n",
    "dc, shares_MinMade96=est_ms_cm(d_MinMade96, th2, data_MinMade96, simpack)\n",
    "\n",
    "data_HH96=(promosize, demog, brands, P_HH96_diff, storeweek,share)\n",
    "dw, shares_HH96=est_ms_cm(d_HH96, th2, data_HH96, simpack)\n",
    "\n",
    "data_Tropic96=(promosize, demog, brands, P_Tropic96_diff, storeweek,share)\n",
    "da, shares_Tropic96=est_ms_cm(d_Tropic96, th2, data_Tropic96, simpack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_1(dif,dataset, filter1, value1, filter2, value2,col_groupby):\n",
    "    data_i=dataset.loc[lambda di: dataset[filter1]==value1,:]\n",
    "    data_m=data_i.loc[lambda df: data_i[filter2]==value2,:]\n",
    "    data_f=data_m.groupby([col_groupby]).sum()\n",
    "    data_f.iloc[:,11]=(data_f.iloc[:,11]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,12]=(data_f.iloc[:,12]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,13]=(data_f.iloc[:,13]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,14]=(data_f.iloc[:,14]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,15]=(data_f.iloc[:,15]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,16]=(data_f.iloc[:,16]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,17]=(data_f.iloc[:,17]-data_f.iloc[:,10])/dif\n",
    "    data_f.iloc[:,18]=(data_f.iloc[:,18]-data_f.iloc[:,10])/dif\n",
    "    return data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29893, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeweek.shape#, promosize, brands, totcount, est_sh_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the filtered data, each row in the 'share_x' columns show the effect in the 'brand' and 'size' market share \n",
    "# of a change in the price of '_x'\n",
    "\n",
    "zone_week=np.array(datapack_GMM['zone'].apply(lambda x: x*1000)+datapack_GMM['week'], ndmin=2).T\n",
    "week=np.array(datapack_GMM['week'], ndmin=2).T\n",
    "totcount = np.array(datapack_GMM['totcount'], ndmin=2).T\n",
    "\n",
    "q_diff = np.hstack((zone_week, week, storeweek, promosize, brands, totcount, est_sh_test, \\\n",
    "                    shares_florida64, shares_MinMade64, shares_MinMade96, \\\n",
    "                    shares_HH64, shares_HH96, shares_Tropic64, shares_Tropic96, shares_TropicSB64))\n",
    "\n",
    "q_diff=pd.DataFrame(q_diff)\n",
    "\n",
    "q_diff.columns = ['zone-week', 'week', 'store-week', 'promo', '64_OZ', 'florida','MinMade','HH','Tropic','TropicSB'\\\n",
    "                  , 'totcount', 'est_sh_eq', 'shares_pf64', 'shares_pm64'\\\n",
    "                  , 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64']\n",
    "\n",
    "h=1e-5\n",
    "\n",
    "sh_florida_64=filter_1(h, q_diff, 'florida', 1, '64_OZ', 1, 'store-week')\n",
    "sh_florida_64['store-week']=sh_florida_64.index.values\n",
    "\n",
    "sh_MinMade_64=filter_1(h, q_diff, 'MinMade', 1, '64_OZ', 1, 'store-week')\n",
    "sh_MinMade_64['store-week']=sh_MinMade_64.index.values\n",
    "\n",
    "sh_MinMade_96=filter_1(h, q_diff, 'MinMade', 1, '64_OZ', 0, 'store-week')\n",
    "sh_MinMade_96['store-week']=sh_MinMade_96.index.values\n",
    "\n",
    "sh_HH_64=filter_1(h, q_diff, 'HH', 1, '64_OZ', 1, 'store-week')\n",
    "sh_HH_64['store-week']=sh_HH_64.index.values\n",
    "\n",
    "sh_HH_96=filter_1(h, q_diff, 'HH', 1, '64_OZ', 0, 'store-week')\n",
    "sh_HH_96['store-week']=sh_HH_96.index.values\n",
    "\n",
    "sh_Tropic_64=filter_1(h, q_diff, 'Tropic', 1, '64_OZ', 1, 'store-week')\n",
    "sh_Tropic_64['store-week']=sh_Tropic_64.index.values\n",
    "\n",
    "sh_Tropic_96=filter_1(h, q_diff, 'Tropic', 1, '64_OZ', 0, 'store-week')\n",
    "sh_Tropic_96['store-week']=sh_Tropic_96.index.values\n",
    "\n",
    "sh_TropicSB_64=filter_1(h, q_diff, 'TropicSB', 1, '64_OZ', 1, 'store-week')\n",
    "sh_TropicSB_64['store-week']=sh_TropicSB_64.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone-week</th>\n",
       "      <th>week</th>\n",
       "      <th>promo</th>\n",
       "      <th>64_OZ</th>\n",
       "      <th>florida</th>\n",
       "      <th>MinMade</th>\n",
       "      <th>HH</th>\n",
       "      <th>Tropic</th>\n",
       "      <th>TropicSB</th>\n",
       "      <th>totcount</th>\n",
       "      <th>est_sh_eq</th>\n",
       "      <th>shares_pf64</th>\n",
       "      <th>shares_pm64</th>\n",
       "      <th>shares_pm96</th>\n",
       "      <th>shares_ph64</th>\n",
       "      <th>shares_ph96</th>\n",
       "      <th>shares_pt64</th>\n",
       "      <th>shares_pt96</th>\n",
       "      <th>shares_ptsb64</th>\n",
       "      <th>store-week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store-week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2173.000000</th>\n",
       "      <td>1173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12672.000000</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>2173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174.000000</th>\n",
       "      <td>1174.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11477.000000</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>2174.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              zone-week       week    promo    64_OZ  florida  MinMade  \\\n",
       "store-week                                                               \n",
       "2173.000000 1173.000000 173.000000 0.000000 1.000000 1.000000 0.000000   \n",
       "2174.000000 1174.000000 174.000000 1.000000 1.000000 1.000000 0.000000   \n",
       "\n",
       "                  HH   Tropic  TropicSB     totcount  est_sh_eq  shares_pf64  \\\n",
       "store-week                                                                     \n",
       "2173.000000 0.000000 0.000000 0.000000  12672.000000 0.001140   0.001043       \n",
       "2174.000000 0.000000 0.000000 0.000000  11477.000000 0.003003   0.002519       \n",
       "\n",
       "             shares_pm64  shares_pm96  shares_ph64  shares_ph96  shares_pt64  \\\n",
       "store-week                                                                     \n",
       "2173.000000 -0.000016    -0.000004    -0.000026    -0.000010    -0.000023      \n",
       "2174.000000 -0.000031    -0.000005    -0.000045    -0.000013    -0.000041      \n",
       "\n",
       "             shares_pt96  shares_ptsb64  store-week  \n",
       "store-week                                           \n",
       "2173.000000 -0.000003    -0.000015      2173.000000  \n",
       "2174.000000 -0.000007    -0.000014      2174.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_florida_64.iloc[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_prices(data, filter1, valuef1, filter2, valuef2, price1, price2, weight_col,groupby_col):\n",
    "    prices_ini=data.loc[lambda pcs: data[filter1]==valuef1,:]\n",
    "    prices_med=prices_ini.loc[lambda pcm: prices_ini[filter2]==valuef2,:]\n",
    "    prices_med['weighted_price'] = prices_med[price1]*prices_med[weight_col]\n",
    "    prices_med['weighted_wprice'] = prices_med[price2]*prices_med[weight_col]\n",
    "    prices_fin = prices_med.groupby([groupby_col]).sum()\n",
    "    prices_fin['weighted_price'] = prices_fin['weighted_price']/prices_fin[weight_col]\n",
    "    prices_fin['weighted_wprice'] = prices_fin['weighted_wprice']/prices_fin[weight_col]\n",
    "#    prices_fin[groupby_col] = prices_fin[groupby_col]/prices_fin[filter1]\n",
    "    return prices_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#It could be possible that a product had not been sold in a store-week, \n",
    "#so for pricing it is necessary to exactly math the cuantities with the respectives products\n",
    "\n",
    "#calculating weighted average store-week price and weighted average store-week wholesale price. This data also includes the\n",
    "#Q total per brand, size, and store-week\n",
    "\n",
    "move=np.array(datapack_GMM[['move']])\n",
    "\n",
    "price_data=np.hstack((zone_week, storeweek, week, promosize, move, brands, price_est, wholeprice))\n",
    "price_data=pd.DataFrame(price_data)\n",
    "\n",
    "price_data.columns = ['zone-week', 'store-week', 'week', 'promo', '64_OZ', 'move', 'florida','MinMade','HH','Tropic',\\\n",
    "                      'TropicSB', 'price_est', 'wholeprice']\n",
    "\n",
    "florida64_prices = weighted_prices(price_data, 'florida', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "florida64_prices['store-week']=florida64_prices.index.values\n",
    "\n",
    "MinMade64_prices = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "MinMade64_prices['store-week']=MinMade64_prices.index.values\n",
    "\n",
    "MinMade96_prices = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "MinMade96_prices['store-week']=MinMade96_prices.index.values\n",
    "\n",
    "HH64_prices = weighted_prices(price_data, 'HH', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "HH64_prices['store-week']=HH64_prices.index.values\n",
    "\n",
    "HH96_prices = weighted_prices(price_data, 'HH', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "HH96_prices['store-week']=HH96_prices.index.values\n",
    "\n",
    "Tropic64_prices = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "Tropic64_prices['store-week']=Tropic64_prices.index.values\n",
    "\n",
    "Tropic96_prices = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "Tropic96_prices['store-week']=Tropic96_prices.index.values\n",
    "\n",
    "TropicSB64_prices = weighted_prices(price_data, 'TropicSB', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'store-week')\n",
    "TropicSB64_prices['store-week']=TropicSB64_prices.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3904,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market2=datapack_GMM['store-week'].drop_duplicates()\n",
    "\n",
    "market2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(data1, data2, common, col1, col2, col3, col4, col5, col6, col7, col8):\n",
    "    m1=data1[common].map(data2.set_index(common)[col1])\n",
    "    m2=data1[common].map(data2.set_index(common)[col2])\n",
    "    m3=data1[common].map(data2.set_index(common)[col3])\n",
    "    m4=data1[common].map(data2.set_index(common)[col4])\n",
    "    m5=data1[common].map(data2.set_index(common)[col5])\n",
    "    m6=data1[common].map(data2.set_index(common)[col6])\n",
    "    m7=data1[common].map(data2.set_index(common)[col7])\n",
    "    m8=data1[common].map(data2.set_index(common)[col8])\n",
    "    mapping=pd.concat([m1, m2, m3, m4, m5, m6, m7, m8], axis=1)\n",
    "    mapping.columns=['shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64']\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['store-week', 'm64']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market2=datapack_GMM['store-week'].drop_duplicates()\n",
    "\n",
    "wholesale_prices_s=pd.DataFrame(datapack_GMM['store-week'])\n",
    "wholesale_prices_s=wholesale_prices_s.drop_duplicates()\n",
    "wholesale_prices_s['m64']=wholesale_prices_s['store-week'].map(MinMade64_prices.set_index('store-week')['weighted_wprice'])\n",
    "list(wholesale_prices_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating equilibrium prices on store configuration\n",
    "\n",
    "market2=datapack_GMM['store-week'].drop_duplicates()\n",
    "\n",
    "wholesale_prices_s=pd.DataFrame(datapack_GMM['store-week'].drop_duplicates())\n",
    "wholesale_prices_s['f64']=wholesale_prices_s['store-week'].map(florida64_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['m64']=wholesale_prices_s['store-week'].map(MinMade64_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['m96']=wholesale_prices_s['store-week'].map(MinMade96_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['h64']=wholesale_prices_s['store-week'].map(HH64_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['h96']=wholesale_prices_s['store-week'].map(HH96_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['t64']=wholesale_prices_s['store-week'].map(Tropic64_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['f96']=wholesale_prices_s['store-week'].map(Tropic96_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s['tsb64']=wholesale_prices_s['store-week'].map(TropicSB64_prices.set_index('store-week')['weighted_wprice'])\n",
    "wholesale_prices_s=wholesale_prices_s.drop(columns=['store-week'], axis=1)\n",
    "\n",
    "elasticities_s=pd.DataFrame(datapack_GMM['store-week'].drop_duplicates())\n",
    "es_f64=mapping(elasticities_s,sh_florida_64,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_m64=mapping(elasticities_s,sh_MinMade_64,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_m96=mapping(elasticities_s,sh_MinMade_96,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_h64=mapping(elasticities_s,sh_HH_64,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_h96=mapping(elasticities_s,sh_HH_96,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_t64=mapping(elasticities_s,sh_Tropic_64,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_t96=mapping(elasticities_s,sh_Tropic_96,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "es_tsb64=mapping(elasticities_s,sh_TropicSB_64,'store-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "\n",
    "elasticities_s=pd.concat([elasticities_s, es_f64,es_m64, es_m96, es_h64,es_h96, es_t64,es_t96, es_tsb64], axis=1)\n",
    "elasticities_s=elasticities_s.drop(columns=['store-week'], axis=1)\n",
    "\n",
    "Quants_s=pd.DataFrame(datapack_GMM['store-week'].drop_duplicates())\n",
    "Quants_s['f64']=Quants_s['store-week'].map(florida64_prices.set_index('store-week')['move'])\n",
    "Quants_s['m64']=Quants_s['store-week'].map(MinMade64_prices.set_index('store-week')['move'])\n",
    "Quants_s['m96']=Quants_s['store-week'].map(MinMade96_prices.set_index('store-week')['move'])\n",
    "Quants_s['h64']=Quants_s['store-week'].map(HH64_prices.set_index('store-week')['move'])\n",
    "Quants_s['h96']=Quants_s['store-week'].map(HH96_prices.set_index('store-week')['move'])\n",
    "Quants_s['t64']=Quants_s['store-week'].map(Tropic64_prices.set_index('store-week')['move'])\n",
    "Quants_s['f96']=Quants_s['store-week'].map(Tropic96_prices.set_index('store-week')['move'])\n",
    "Quants_s['tsb64']=Quants_s['store-week'].map(TropicSB64_prices.set_index('store-week')['move'])\n",
    "Quants_s=Quants_s.drop(columns=['store-week'], axis=1)\n",
    "\n",
    "opt_price_ST = pd.concat([market2, wholesale_prices_s, elasticities_s, Quants_s], axis=1, sort=False)\n",
    "\n",
    "opt_pricesST_matrix=np.zeros((market2.size,8))\n",
    "\n",
    "for i in range(market2.shape[0]):\n",
    "    omega=np.vstack([[opt_price_ST.iloc[i,9:17]],[opt_price_ST.iloc[i,17:25]],[opt_price_ST.iloc[i,25:33]]\\\n",
    "                     ,[opt_price_ST.iloc[i,33:41]],[opt_price_ST.iloc[i,41:49]],[opt_price_ST.iloc[i,49:57]]\\\n",
    "                     ,[opt_price_ST.iloc[i,57:65]],[opt_price_ST.iloc[i,65:73]]])\n",
    "    omega_inv=lin.inv(omega)\n",
    "    whpr=np.reshape(np.array(opt_price_ST.iloc[i,1:9]),(8,1)) - omega_inv@np.reshape(np.array(opt_price_ST.iloc[i,73:81]),(8,1))\n",
    "    opt_pricesST_matrix[i,:]=whpr.T\n",
    "    i+=1\n",
    "\n",
    "market2=np.array(market2,ndmin=2).T\n",
    "\n",
    "opt_pricesST_matrix=np.hstack((market2, opt_pricesST_matrix))\n",
    "\n",
    "opt_pricesST=pd.DataFrame(opt_pricesST_matrix)\n",
    "opt_pricesST.columns=['store-week','f64_s', 'm64_s', 'm96_s', 'h64_s', 'h96_s', 't64_s', 't96_s', 'tsb64_s']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zone configuration\n",
    "\n",
    "What did I do?: i) to calculate dq/dp for each zone-week, using the weighted average per store shares (wieghted by totalcount), ii) to calculate weighted average prices and wholesale prices for zone-week, and, iii) using dp/dq, quantities and wholesale prices, calculate the equilibrium price for this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_2(dif,dataset, filter1, value1, filter2, value2,col_groupby1, col_groupby2, weight):\n",
    "    data_i=dataset.loc[lambda di: dataset[filter1]==value1,:]\n",
    "    data_m=data_i.loc[lambda df: data_i[filter2]==value2,:]\n",
    "    data_m=data_m.groupby([col_groupby1]).sum()\n",
    "    data_m.iloc[:,11]=data_m.iloc[:,11]*data_m[weight]\n",
    "    data_m.iloc[:,12]=data_m.iloc[:,12]*data_m[weight]\n",
    "    data_m.iloc[:,13]=data_m.iloc[:,13]*data_m[weight]\n",
    "    data_m.iloc[:,14]=data_m.iloc[:,14]*data_m[weight]\n",
    "    data_m.iloc[:,15]=data_m.iloc[:,15]*data_m[weight]\n",
    "    data_m.iloc[:,16]=data_m.iloc[:,16]*data_m[weight]\n",
    "    data_m.iloc[:,17]=data_m.iloc[:,17]*data_m[weight]\n",
    "    data_m.iloc[:,18]=data_m.iloc[:,18]*data_m[weight]\n",
    "    data_f=data_m.groupby([col_groupby2]).sum()\n",
    "    data_f.iloc[:,10]=data_f.iloc[:,10]*data_f[weight]\n",
    "    data_f.iloc[:,11]=data_f.iloc[:,11]*data_f[weight]\n",
    "    data_f.iloc[:,12]=data_f.iloc[:,12]*data_f[weight]\n",
    "    data_f.iloc[:,13]=data_f.iloc[:,13]*data_f[weight]\n",
    "    data_f.iloc[:,14]=data_f.iloc[:,14]*data_f[weight]\n",
    "    data_f.iloc[:,15]=data_f.iloc[:,15]*data_f[weight]\n",
    "    data_f.iloc[:,16]=data_f.iloc[:,16]*data_f[weight]\n",
    "    data_f.iloc[:,17]=data_f.iloc[:,17]*data_f[weight]\n",
    "#    data_f[col_groupby1] = data_f[col_groupby1]/data_f[filter1]\n",
    "#    data_f[col_groupby2] = data_f[col_groupby2]/data_f[filter1]\n",
    "    data_f.iloc[:,10]=(data_f.iloc[:,10]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,11]=(data_f.iloc[:,11]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,12]=(data_f.iloc[:,12]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,13]=(data_f.iloc[:,13]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,14]=(data_f.iloc[:,14]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,15]=(data_f.iloc[:,15]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,16]=(data_f.iloc[:,16]-data_f.iloc[:,9])/dif\n",
    "    data_f.iloc[:,17]=(data_f.iloc[:,17]-data_f.iloc[:,9])/dif\n",
    "    return data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_f64_zone=filter_2(h, q_diff, 'florida', 1, '64_OZ', 1, 'store-week', 'zone-week', 'totcount')\n",
    "sh_f64_zone['zone-week']=sh_f64_zone.index.values\n",
    "\n",
    "sh_m64_zone=filter_2(h, q_diff, 'MinMade', 1, '64_OZ', 1, 'store-week', 'zone-week', 'totcount')\n",
    "sh_m64_zone['zone-week']=sh_m64_zone.index.values\n",
    "\n",
    "sh_m96_zone=filter_2(h, q_diff, 'MinMade', 1, '64_OZ', 0, 'store-week', 'zone-week', 'totcount')\n",
    "sh_m96_zone['zone-week']=sh_m96_zone.index.values\n",
    "\n",
    "sh_h64_zone=filter_2(h, q_diff, 'HH', 1, '64_OZ', 1, 'store-week', 'zone-week', 'totcount')\n",
    "sh_h64_zone['zone-week']=sh_h64_zone.index.values\n",
    "\n",
    "sh_h96_zone=filter_2(h, q_diff, 'HH', 1, '64_OZ', 0, 'store-week', 'zone-week', 'totcount')\n",
    "sh_h96_zone['zone-week']=sh_h96_zone.index.values\n",
    "\n",
    "sh_t64_zone=filter_2(h, q_diff, 'Tropic', 1, '64_OZ', 1, 'store-week', 'zone-week', 'totcount')\n",
    "sh_t64_zone['zone-week']=sh_t64_zone.index.values\n",
    "\n",
    "sh_t96_zone=filter_2(h, q_diff, 'Tropic', 1, '64_OZ', 0, 'store-week', 'zone-week', 'totcount')\n",
    "sh_t96_zone['zone-week']=sh_t96_zone.index.values\n",
    "\n",
    "sh_tsb64_zone=filter_2(h, q_diff, 'TropicSB', 1, '64_OZ', 1, 'store-week', 'zone-week', 'totcount')\n",
    "sh_tsb64_zone['zone-week']=sh_tsb64_zone.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "f64_prices_zone = weighted_prices(price_data, 'florida', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "f64_prices_zone['zone-week']=f64_prices_zone.index.values\n",
    "\n",
    "m64_prices_zone = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "m64_prices_zone['zone-week']=m64_prices_zone.index.values\n",
    "\n",
    "m96_prices_zone = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "m96_prices_zone['zone-week']=m96_prices_zone.index.values\n",
    "\n",
    "h64_prices_zone = weighted_prices(price_data, 'HH', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "h64_prices_zone['zone-week']=h64_prices_zone.index.values\n",
    "\n",
    "h96_prices_zone = weighted_prices(price_data, 'HH', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "h96_prices_zone['zone-week']=h96_prices_zone.index.values\n",
    "\n",
    "t64_prices_zone = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "t64_prices_zone['zone-week']=t64_prices_zone.index.values\n",
    "\n",
    "t96_prices_zone = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "t96_prices_zone['zone-week']=t96_prices_zone.index.values\n",
    "\n",
    "tsb64_prices_zone = weighted_prices(price_data, 'TropicSB', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'zone-week')\n",
    "tsb64_prices_zone['zone-week']=tsb64_prices_zone.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculating equilibrium prices on zone configuration\n",
    "\n",
    "zone_week=pd.DataFrame(zone_week)\n",
    "market3=zone_week.drop_duplicates()\n",
    "\n",
    "\n",
    "wholesale_prices_z=zone_week.drop_duplicates()\n",
    "wholesale_prices_z.columns=['zone-week']\n",
    "wholesale_prices_z['f64']=wholesale_prices_z['zone-week'].map(f64_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['m64']=wholesale_prices_z['zone-week'].map(m64_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['m96']=wholesale_prices_z['zone-week'].map(m96_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['h64']=wholesale_prices_z['zone-week'].map(h64_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['h96']=wholesale_prices_z['zone-week'].map(h96_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['t64']=wholesale_prices_z['zone-week'].map(t64_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['f96']=wholesale_prices_z['zone-week'].map(t96_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z['tsb64']=wholesale_prices_z['zone-week'].map(tsb64_prices_zone.set_index('zone-week')['weighted_wprice'])\n",
    "wholesale_prices_z=wholesale_prices_z.drop(columns=['zone-week'], axis=1)\n",
    "\n",
    "\n",
    "elasticities_z=zone_week.drop_duplicates()\n",
    "elasticities_z.columns=['zone-week']\n",
    "ez_f64=mapping(elasticities_z,sh_f64_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_m64=mapping(elasticities_z,sh_m64_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_m96=mapping(elasticities_z,sh_m96_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_h64=mapping(elasticities_z,sh_h64_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_h96=mapping(elasticities_z,sh_h96_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_t64=mapping(elasticities_z,sh_t64_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_t96=mapping(elasticities_z,sh_t96_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ez_tsb64=mapping(elasticities_z,sh_tsb64_zone,'zone-week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "\n",
    "elasticities_z=pd.concat([elasticities_z, ez_f64,ez_m64, ez_m96, ez_h64,ez_h96, ez_t64,ez_t96, ez_tsb64], axis=1)\n",
    "elasticities_z=elasticities_z.drop(columns=['zone-week'], axis=1)\n",
    "\n",
    "Quants_z=zone_week.drop_duplicates()\n",
    "Quants_z.columns=['zone-week']\n",
    "Quants_z['f64']=Quants_z['zone-week'].map(f64_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['m64']=Quants_z['zone-week'].map(m64_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['m96']=Quants_z['zone-week'].map(m96_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['h64']=Quants_z['zone-week'].map(h64_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['h96']=Quants_z['zone-week'].map(h96_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['t64']=Quants_z['zone-week'].map(t64_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['f96']=Quants_z['zone-week'].map(t96_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z['tsb64']=Quants_z['zone-week'].map(tsb64_prices_zone.set_index('zone-week')['move'])\n",
    "Quants_z=Quants_z.drop(columns=['zone-week'], axis=1)\n",
    "\n",
    "opt_price_ZN = np.hstack((market3, wholesale_prices_z, elasticities_z, Quants_z))\n",
    "\n",
    "opt_price_ZN = pd.DataFrame(opt_price_ZN)\n",
    "\n",
    "opt_pricesZN_matrix=np.zeros((market3.size,8))\n",
    "i=0\n",
    "for i in range(market3.shape[0]):\n",
    "    omegaZN=np.vstack([[opt_price_ZN.iloc[i,9:17]],[opt_price_ZN.iloc[i,17:25]],[opt_price_ZN.iloc[i,25:33]]\\\n",
    "                     ,[opt_price_ZN.iloc[i,33:41]],[opt_price_ZN.iloc[i,41:49]],[opt_price_ZN.iloc[i,49:57]]\\\n",
    "                     ,[opt_price_ZN.iloc[i,57:65]],[opt_price_ZN.iloc[i,65:73]]])\n",
    "    omegaZN_inv=lin.inv(omegaZN)\n",
    "    whprZN=np.reshape(np.array(opt_price_ZN.iloc[i,1:9]),(8,1)) - \\\n",
    "    omegaZN_inv@np.reshape(np.array(opt_price_ZN.iloc[i,73:81]),(8,1))\n",
    "    opt_pricesZN_matrix[i,:]=whprZN.T\n",
    "    i+=1\n",
    "\n",
    "market3=np.array(market3,ndmin=2)\n",
    "\n",
    "opt_pricesZN_matrix=np.hstack((market3, opt_pricesZN_matrix))\n",
    "\n",
    "opt_pricesZN=pd.DataFrame(opt_pricesZN_matrix)\n",
    "opt_pricesZN.columns=['zone-week','f64_z', 'm64_z', 'm96_z', 'h64_z', 'h96_z', 't64_z', 't96_z', 'tsb64_z']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain configuration\n",
    "\n",
    "What did I do?: i) to calculate dq/dp for each week, using the weighted average per store shares (wieghted by totalcount), ii) to calculate weighted average prices and wholesale prices for  each week, and, iii) using dp/dq, quantities and wholesale prices, calculate the equilibrium price for this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_f64_chain=filter_2(h, q_diff, 'florida', 1, '64_OZ', 1, 'store-week', 'week', 'totcount')\n",
    "sh_f64_chain['week']=sh_f64_chain.index.values\n",
    "\n",
    "sh_m64_chain=filter_2(h, q_diff, 'MinMade', 1, '64_OZ', 1, 'store-week', 'week', 'totcount')\n",
    "sh_m64_chain['week']=sh_m64_chain.index.values\n",
    "\n",
    "sh_m96_chain=filter_2(h, q_diff, 'MinMade', 1, '64_OZ', 0, 'store-week', 'week', 'totcount')\n",
    "sh_m96_chain['week']=sh_m96_chain.index.values\n",
    "\n",
    "sh_h64_chain=filter_2(h, q_diff, 'HH', 1, '64_OZ', 1, 'store-week', 'week', 'totcount')\n",
    "sh_h64_chain['week']=sh_h64_chain.index.values\n",
    "\n",
    "sh_h96_chain=filter_2(h, q_diff, 'HH', 1, '64_OZ', 0, 'store-week', 'week', 'totcount')\n",
    "sh_h96_chain['week']=sh_h96_chain.index.values\n",
    "\n",
    "sh_t64_chain=filter_2(h, q_diff, 'Tropic', 1, '64_OZ', 1, 'store-week', 'week', 'totcount')\n",
    "sh_t64_chain['week']=sh_t64_chain.index.values\n",
    "\n",
    "sh_t96_chain=filter_2(h, q_diff, 'Tropic', 1, '64_OZ', 0, 'store-week', 'week', 'totcount')\n",
    "sh_t96_chain['week']=sh_t96_chain.index.values\n",
    "\n",
    "sh_tsb64_chain=filter_2(h, q_diff, 'TropicSB', 1, '64_OZ', 1, 'store-week', 'week', 'totcount')\n",
    "sh_tsb64_chain['week']=sh_tsb64_chain.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "f64_prices_chain = weighted_prices(price_data, 'florida', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'week')\n",
    "f64_prices_chain['week']=f64_prices_chain.index.values\n",
    "\n",
    "m64_prices_chain = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'week')\n",
    "m64_prices_chain['week']=m64_prices_chain.index.values\n",
    "\n",
    "m96_prices_chain = weighted_prices(price_data, 'MinMade', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'week')\n",
    "m96_prices_chain['week']=m96_prices_chain.index.values\n",
    "\n",
    "h64_prices_chain = weighted_prices(price_data, 'HH', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'week')\n",
    "h64_prices_chain['week']=h64_prices_chain.index.values\n",
    "\n",
    "h96_prices_chain = weighted_prices(price_data, 'HH', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'week')\n",
    "h96_prices_chain['week']=h96_prices_chain.index.values\n",
    "\n",
    "t64_prices_chain = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'week')\n",
    "t64_prices_chain['week']=t64_prices_chain.index.values\n",
    "\n",
    "t96_prices_chain = weighted_prices(price_data, 'Tropic', 1, '64_OZ', 0, 'price_est', 'wholeprice', 'move', 'week')\n",
    "t96_prices_chain['week']=t96_prices_chain.index.values\n",
    "\n",
    "tsb64_prices_chain = weighted_prices(price_data, 'TropicSB', 1, '64_OZ', 1, 'price_est', 'wholeprice', 'move', 'week')\n",
    "tsb64_prices_chain['week']=tsb64_prices_chain.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#calculating equilibrium prices on chain configuration\n",
    "\n",
    "week=pd.DataFrame(week)\n",
    "market4=week.drop_duplicates()\n",
    "\n",
    "wholesale_prices_c=week.drop_duplicates()\n",
    "wholesale_prices_c.columns=['week']\n",
    "wholesale_prices_c['f64']=wholesale_prices_c['week'].map(f64_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['m64']=wholesale_prices_c['week'].map(m64_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['m96']=wholesale_prices_c['week'].map(m96_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['h64']=wholesale_prices_c['week'].map(h64_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['h96']=wholesale_prices_c['week'].map(h96_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['t64']=wholesale_prices_c['week'].map(t64_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['f96']=wholesale_prices_c['week'].map(t96_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c['tsb64']=wholesale_prices_c['week'].map(tsb64_prices_chain.set_index('week')['weighted_wprice'])\n",
    "wholesale_prices_c=wholesale_prices_c.drop(columns=['week'], axis=1)\n",
    "\n",
    "elasticities_c=week.drop_duplicates()\n",
    "elasticities_c.columns=['week']\n",
    "ec_f64=mapping(elasticities_c,sh_f64_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_m64=mapping(elasticities_c,sh_m64_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_m96=mapping(elasticities_c,sh_m96_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_h64=mapping(elasticities_c,sh_h64_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_h96=mapping(elasticities_c,sh_h96_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_t64=mapping(elasticities_c,sh_t64_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_t96=mapping(elasticities_c,sh_t96_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "ec_tsb64=mapping(elasticities_c,sh_tsb64_chain,'week','shares_pf64', 'shares_pm64', 'shares_pm96', 'shares_ph64', 'shares_ph96', 'shares_pt64', 'shares_pt96', 'shares_ptsb64')\n",
    "\n",
    "elasticities_c=pd.concat([elasticities_c, ec_f64,ec_m64, ec_m96, ec_h64,ec_h96, ec_t64,ec_t96, ec_tsb64], axis=1)\n",
    "elasticities_c=elasticities_c.drop(columns=['week'], axis=1)\n",
    "\n",
    "Quants_c=week.drop_duplicates()\n",
    "Quants_c.columns=['week']\n",
    "Quants_c['f64']=Quants_c['week'].map(f64_prices_chain.set_index('week')['move'])\n",
    "Quants_c['m64']=Quants_c['week'].map(m64_prices_chain.set_index('week')['move'])\n",
    "Quants_c['m96']=Quants_c['week'].map(m96_prices_chain.set_index('week')['move'])\n",
    "Quants_c['h64']=Quants_c['week'].map(h64_prices_chain.set_index('week')['move'])\n",
    "Quants_c['h96']=Quants_c['week'].map(h96_prices_chain.set_index('week')['move'])\n",
    "Quants_c['t64']=Quants_c['week'].map(t64_prices_chain.set_index('week')['move'])\n",
    "Quants_c['f96']=Quants_c['week'].map(t96_prices_chain.set_index('week')['move'])\n",
    "Quants_c['tsb64']=Quants_c['week'].map(tsb64_prices_chain.set_index('week')['move'])\n",
    "Quants_c=Quants_c.drop(columns=['week'], axis=1)\n",
    "\n",
    "\n",
    "opt_price_CH = pd.concat([market4, wholesale_prices_c, elasticities_c, Quants_c], axis=1)\n",
    "\n",
    "opt_pricesCH_matrix=np.zeros((market4.size,8))\n",
    "\n",
    "for i in range(market4.shape[0]):\n",
    "    omegaCH=np.vstack([[opt_price_CH.iloc[i,9:17]],[opt_price_CH.iloc[i,17:25]],[opt_price_CH.iloc[i,25:33]]\\\n",
    "                     ,[opt_price_CH.iloc[i,33:41]],[opt_price_CH.iloc[i,41:49]],[opt_price_CH.iloc[i,49:57]]\\\n",
    "                     ,[opt_price_CH.iloc[i,57:65]],[opt_price_CH.iloc[i,65:73]]])\n",
    "    omegaCH_inv=lin.inv(omegaCH)\n",
    "    whprCH=np.reshape(np.array(opt_price_CH.iloc[i,1:9]),(8,1)) - \\\n",
    "    omegaCH_inv@np.reshape(np.array(opt_price_CH.iloc[i,73:81]),(8,1))\n",
    "    opt_pricesCH_matrix[i,:]=whprCH.T\n",
    "    i+=1\n",
    "\n",
    "opt_pricesCH_matrix=np.hstack((market4, opt_pricesCH_matrix))\n",
    "\n",
    "opt_pricesCH=pd.DataFrame(opt_pricesCH_matrix)\n",
    "opt_pricesCH.columns=['week','f64_c', 'm64_c', 'm96_c', 'h64_c', 'h96_c', 't64_c', 't96_c', 'tsb64_c']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Welfare\n",
    "\n",
    "## Chain vs Store\n",
    "\n",
    "What did I do?: i) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the store-week dataset.\n",
    "\n",
    "\n",
    "datapack_cws = np.hstack((zone_week, datapack_GMM[['zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                                            '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']]))\n",
    "\n",
    "datapack_cws=pd.DataFrame(datapack_cws)\n",
    "\n",
    "datapack_cws.columns = ['zone-week', 'zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                        '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']\n",
    "\n",
    "datapack_cws['income']=datapack_cws['store'].map(zones.set_index('store')['income'])\n",
    "datapack_cws['AGE60']=datapack_cws['store'].map(zones.set_index('store')['AGE60'])\n",
    "datapack_cws['ethnic']=datapack_cws['store'].map(zones.set_index('store')['ethnic'])\n",
    "datapack_cws['hvalmean']=datapack_cws['store'].map(zones.set_index('store')['hvalmean'])\n",
    "datapack_cws['shopindx']=datapack_cws['store'].map(zones.set_index('store')['shopindx'])\n",
    "datapack_cws['cubdist']=datapack_cws['store'].map(zones.set_index('store')['cubdist'])\n",
    "datapack_cws['omnidist']=datapack_cws['store'].map(zones.set_index('store')['omnidist'])\n",
    "datapack_cws['sstrdist']=datapack_cws['store'].map(zones.set_index('store')['sstrdist'])\n",
    "datapack_cws['dtdist']=datapack_cws['store'].map(zones.set_index('store')['dtdist'])\n",
    "\n",
    "datapack_cws['pf64'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['f64_s'])*datapack_cws['64 OZ']*datapack_cws['florida']\n",
    "\n",
    "datapack_cws['pm64'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['m64_s'])*datapack_cws['64 OZ']*datapack_cws['MinMade']\n",
    "\n",
    "datapack_cws['pm96'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['m96_s'])*datapack_cws['96 OZ']*datapack_cws['MinMade']\n",
    "\n",
    "datapack_cws['ph64'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['h64_s'])*datapack_cws['64 OZ']*datapack_cws['HH']\n",
    "\n",
    "datapack_cws['ph96'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['h96_s'])*datapack_cws['96 OZ']*datapack_cws['HH']\n",
    "\n",
    "datapack_cws['pt64'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['t64_s'])*datapack_cws['64 OZ']*datapack_cws['Tropic']\n",
    "\n",
    "datapack_cws['pt96'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['t96_s'])*datapack_cws['96 OZ']*datapack_cws['Tropic']\n",
    "\n",
    "datapack_cws['ptsb64'] = datapack_cws['store-week'].map(opt_pricesST.set_index('store-week')['tsb64_s'])*datapack_cws['64 OZ']*datapack_cws['TropicSB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cubdist</th>\n",
       "      <th>omnidist</th>\n",
       "      <th>sstrdist</th>\n",
       "      <th>dtdist</th>\n",
       "      <th>pf64</th>\n",
       "      <th>pm64</th>\n",
       "      <th>pm96</th>\n",
       "      <th>ph64</th>\n",
       "      <th>ph96</th>\n",
       "      <th>pt64</th>\n",
       "      <th>pt96</th>\n",
       "      <th>ptsb64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.784829</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.702432</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-93042.408591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.784829</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.702432</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-37718.492917</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.784829</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.702432</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-15672.874545</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.784829</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.702432</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-13306.889406</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.784829</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>2.110122</td>\n",
       "      <td>1.702432</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-14578.238117</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cubdist  omnidist  sstrdist   dtdist      pf64      pm64      pm96  \\\n",
       "0 3.784829 2.110122  2.110122  1.702432 -0.000000 -0.000000 -0.000000   \n",
       "1 3.784829 2.110122  2.110122  1.702432 -0.000000 -0.000000 -0.000000   \n",
       "2 3.784829 2.110122  2.110122  1.702432 -0.000000 -0.000000 -0.000000   \n",
       "3 3.784829 2.110122  2.110122  1.702432 -0.000000 -0.000000 -0.000000   \n",
       "4 3.784829 2.110122  2.110122  1.702432 -0.000000 -0.000000 -0.000000   \n",
       "\n",
       "           ph64          ph96          pt64          pt96        ptsb64  \n",
       "0 -0.000000     -0.000000     -0.000000     -0.000000     -93042.408591  \n",
       "1 -0.000000     -0.000000     -0.000000     -37718.492917 -0.000000      \n",
       "2 -0.000000     -0.000000     -15672.874545 -0.000000     -0.000000      \n",
       "3 -0.000000     -13306.889406 -0.000000     -0.000000     -0.000000      \n",
       "4 -14578.238117 -0.000000     -0.000000     -0.000000     -0.000000      "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapack_cws.iloc[:5,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1027: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    }
   ],
   "source": [
    "# Building the zone-week dataset.\n",
    "\n",
    "\n",
    "datapack_cwz = np.hstack((zone_week, datapack_GMM[['zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                                            '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']]))\n",
    "\n",
    "datapack_cwz=pd.DataFrame(datapack_cwz)\n",
    "\n",
    "datapack_cwz.columns = ['zone-week', 'zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                        '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']\n",
    "\n",
    "\n",
    "datapack_cwz['income']=datapack_cwz['store'].map(zones.set_index('store')['income'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['AGE60']=datapack_cwz['store'].map(zones.set_index('store')['AGE60'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['ethnic']=datapack_cwz['store'].map(zones.set_index('store')['ethnic'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['hvalmean']=datapack_cwz['store'].map(zones.set_index('store')['hvalmean'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['shopindx']=datapack_cwz['store'].map(zones.set_index('store')['shopindx'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['cubdist']=datapack_cwz['store'].map(zones.set_index('store')['cubdist'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['omnidist']=datapack_cwz['store'].map(zones.set_index('store')['omnidist'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['sstrdist']=datapack_cwz['store'].map(zones.set_index('store')['sstrdist'])#*datapack_cwz['totcount']\n",
    "datapack_cwz['dtdist']=datapack_cwz['store'].map(zones.set_index('store')['dtdist'])#*datapack_cwz['totcount']\n",
    "\n",
    "\n",
    "index_cwz = datapack_cwz.index.values\n",
    "\n",
    "datapack_cwz['pf64'] = f64_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['64 OZ']*datapack_cwz['florida']\n",
    "\n",
    "datapack_cwz['pm64'] = m64_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['64 OZ']*datapack_cwz['MinMade']\n",
    "\n",
    "datapack_cwz['pm96'] = m96_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['96 OZ']*datapack_cwz['MinMade']\n",
    "\n",
    "datapack_cwz['ph64'] = h64_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['64 OZ']*datapack_cwz['HH']\n",
    "\n",
    "datapack_cwz['ph96'] = h96_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['96 OZ']*datapack_cwz['HH']\n",
    "\n",
    "datapack_cwz['pt64'] = h64_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['64 OZ']*datapack_cwz['Tropic']\n",
    "\n",
    "datapack_cwz['pt96'] = h96_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['96 OZ']*datapack_cwz['Tropic']\n",
    "\n",
    "datapack_cwz['ptsb64'] = tsb64_prices_zone.loc[index_cwz[:],'weighted_price']*datapack_cwz['64 OZ']*datapack_cwz['TropicSB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29893, 32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapack_cwz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the chain-week dataset.\n",
    "\n",
    "\n",
    "datapack_cwc = np.hstack((zone_week, datapack_GMM[['zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                                            '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']]))\n",
    "\n",
    "datapack_cwc=pd.DataFrame(datapack_cwc)\n",
    "\n",
    "datapack_cwc.columns = ['zone-week', 'zone', 'week', 'store', 'store-week','totcount', 'move', 'promo',\\\n",
    "                        '64 OZ', '96 OZ', 'florida','MinMade','HH','Tropic','TropicSB']\n",
    "\n",
    " \n",
    "datapack_cwc['income']=datapack_cwc['store'].map(zones.set_index('store')['income'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['AGE60']=datapack_cwc['store'].map(zones.set_index('store')['AGE60'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['ethnic']=datapack_cwc['store'].map(zones.set_index('store')['ethnic'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['hvalmean']=datapack_cwc['store'].map(zones.set_index('store')['hvalmean'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['shopindx']=datapack_cwc['store'].map(zones.set_index('store')['shopindx'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['cubdist']=datapack_cwc['store'].map(zones.set_index('store')['cubdist'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['omnidist']=datapack_cwc['store'].map(zones.set_index('store')['omnidist'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['sstrdist']=datapack_cwc['store'].map(zones.set_index('store')['sstrdist'])#*datapack_cwc['totcount']\n",
    "datapack_cwc['dtdist']=datapack_cwc['store'].map(zones.set_index('store')['dtdist'])#*datapack_cwc['totcount']\n",
    "\n",
    "\n",
    "index_cwc = datapack_cwc.index.values\n",
    "\n",
    "datapack_cwc['pf64'] = f64_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['64 OZ']*datapack_cwc['florida']\n",
    "\n",
    "datapack_cwc['pm64'] = m64_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['64 OZ']*datapack_cwc['MinMade']\n",
    "\n",
    "datapack_cwc['pm96'] = m96_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['96 OZ']*datapack_cwc['MinMade']\n",
    "\n",
    "datapack_cwc['ph64'] = h64_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['64 OZ']*datapack_cwc['HH']\n",
    "\n",
    "datapack_cwc['ph96'] = h96_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['96 OZ']*datapack_cwc['HH']\n",
    "\n",
    "datapack_cwc['pt64'] = t64_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['64 OZ']*datapack_cwc['Tropic']\n",
    "\n",
    "datapack_cwc['pt96'] = t96_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['96 OZ']*datapack_cwc['Tropic']\n",
    "\n",
    "datapack_cwc['ptsb64'] = tsb64_prices_chain.loc[index_cwc[:],'weighted_price']*datapack_cwc['64 OZ']*datapack_cwc['TropicSB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating differences in consumer welfare\n",
    "What did I do?: i) prepare the data to generate the deltas and the mu. ii) calculate the deltas and mu for each configuration. iii) group by store-week. iv) take logs. v) calculate the numerator. vi) divide by $\\theta$. vii) take average across simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\n",
    "# draws:\n",
    "\n",
    "#normal_beta_draws\n",
    "#normal_theta_draws\n",
    "#normal_w_draws\n",
    "\n",
    "# store configuration:\n",
    "\n",
    "promo_size_s = np.array(datapack_cws[['promo', '64 OZ']])\n",
    "demog_data_s = np.array(datapack_cws[['income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist']])\n",
    "brand_dummies_s = np.array(datapack_cws[['florida','MinMade','HH','Tropic','TropicSB']])\n",
    "storeweek_s = np.array(datapack_cws['store-week'])\n",
    "\n",
    "price1_s = datapack_cws[['pf64', 'pm64', 'pm96', 'ph64', 'ph96', 'pt64', 'pt96', 'ptsb64']]\n",
    "price2_s = price1_s.sum(axis=1)\n",
    "price_s = np.array(price2_s, ndmin=2).T\n",
    "\n",
    "# zone configuration:\n",
    "\n",
    "promo_size_z = np.array(datapack_cwz[['promo', '64 OZ']])\n",
    "demog_data_z = np.array(datapack_cwz[['income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist']])\n",
    "brand_dummies_z = np.array(datapack_cwz[['florida','MinMade','HH','Tropic','TropicSB']])\n",
    "storeweek_z = np.array(datapack_cwz['store-week'])\n",
    "\n",
    "price1_z = datapack_cwz[['pf64', 'pm64', 'pm96', 'ph64', 'ph96', 'pt64', 'pt96', 'ptsb64']]\n",
    "price2_z = price1_z.sum(axis=1)\n",
    "price_z = np.array(price2_z, ndmin=2).T\n",
    "\n",
    "# chain configuration:\n",
    "\n",
    "promo_size_c = np.array(datapack_cwc[['promo', '64 OZ']])\n",
    "demog_data_c = np.array(datapack_cwc[['income', 'AGE60', 'ethnic', 'hvalmean','shopindx','sstrdist']])\n",
    "brand_dummies_c = np.array(datapack_cwc[['florida','MinMade','HH','Tropic','TropicSB']])\n",
    "storeweek_c = np.array(datapack_cwc['store-week'])\n",
    "\n",
    "price1_c = datapack_cwc[['pf64', 'pm64', 'pm96', 'ph64', 'ph96', 'pt64', 'pt96', 'ptsb64']]\n",
    "price2_c = price1_c.sum(axis=1)\n",
    "price_c = np.array(price2_c, ndmin=2).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating deltas and mu for each configuration:\n",
    "\n",
    "# draws:\n",
    "\n",
    "#normal_beta_draws\n",
    "#normal_theta_draws\n",
    "#normal_w_draws\n",
    "\n",
    "# store configuration:\n",
    "\n",
    "xi_s=np.zeros((datapack_cws.shape[0],1))\n",
    "\n",
    "delta_s = delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi_s, \\\n",
    "                     promo_size_s, demog_data_s, brand_dummies_s, price_s, storeweek_s)\n",
    "\n",
    "mu_s = mu_fun(promo_size_s, price_s, brand_dummies_s, L_matrix_def, lambda_p_s_def,\\\n",
    "              lambda_price_def, normal_beta_draws, normal_theta_draws, normal_w_draws)\n",
    "\n",
    "# zone configuration:\n",
    "\n",
    "xi_z=np.zeros((datapack_cwz.shape[0],1))\n",
    "\n",
    "delta_z = delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi_z, \\\n",
    "                     promo_size_z, demog_data_z, brand_dummies_z, price_z, storeweek_z)\n",
    "\n",
    "mu_z = mu_fun(promo_size_z, price_z, brand_dummies_z, L_matrix_def, lambda_p_s_def,\\\n",
    "              lambda_price_def, normal_beta_draws, normal_theta_draws, normal_w_draws)\n",
    "\n",
    "# chain configuration:\n",
    "\n",
    "xi_c=np.zeros((datapack_cwc.shape[0],1))\n",
    "\n",
    "delta_c = delta_fun(alpha_def, beta_def, sigma_def, gamma_def, theta_def, xi_c, \\\n",
    "                     promo_size_c, demog_data_c, brand_dummies_c, price_c, storeweek_c)\n",
    "\n",
    "mu_c = mu_fun(promo_size_c, price_c, brand_dummies_c, L_matrix_def, lambda_p_s_def,\\\n",
    "              lambda_price_def, normal_beta_draws, normal_theta_draws, normal_w_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4ac6d69442a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# store configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdelta_s2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mexp_ut1_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta_s2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmu_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# adding up, taking exponential, grouping by store_week and taking logs\n",
    "\n",
    "# store configuration\n",
    "\n",
    "delta_s2=np.array(delta_s[:,1], ndmin=2).T\n",
    "\n",
    "exp_ut1_s = delta_s2 + mu_s\n",
    "exp_ut2_s = np.exp(exp_ut1_s)\n",
    "exp_ut2_s = pd.DataFrame(exp_ut2_s)\n",
    "exp_ut2_s = 1 + exp_ut2_s\n",
    "exp_ut2_s['store-week'] = datapack_cws['store-week']\n",
    "exp_ut3_s = exp_ut2_s.groupby(['store-week']).sum()\n",
    "exp_ut3_s = np.log(exp_ut3_s)\n",
    "\n",
    "log_expected_ut_s = exp_ut3_s\n",
    "\n",
    "# zone configuration\n",
    "\n",
    "delta_z2=np.array(delta_z[:,1], ndmin=2).T\n",
    "\n",
    "exp_ut1_z = delta_z2 + mu_z\n",
    "exp_ut2_z = np.exp(exp_ut1_z)\n",
    "exp_ut2_z = pd.DataFrame(exp_ut2_z)\n",
    "exp_ut2_z = 1 + exp_ut2_z\n",
    "exp_ut2_z['store-week'] = datapack_cwz['store-week']\n",
    "exp_ut3_z = exp_ut2_z.groupby(['store-week']).sum()\n",
    "exp_ut3_z = np.log(exp_ut3_z)\n",
    "\n",
    "log_expected_ut_z = exp_ut3_z\n",
    "\n",
    "# chain configuration\n",
    "\n",
    "delta_c2=np.array(delta_c[:,1], ndmin=2).T\n",
    "\n",
    "exp_ut1_c = delta_c2 + mu_c\n",
    "exp_ut2_c = np.exp(exp_ut1_c)\n",
    "exp_ut2_c = pd.DataFrame(exp_ut2_c)\n",
    "exp_ut2_c = 1 + exp_ut2_c\n",
    "exp_ut2_c['store-week'] = datapack_cwc['store-week2']\n",
    "exp_ut3_c = exp_ut2_c.groupby(['store-week']).sum()\n",
    "exp_ut3_c = np.log(exp_ut2_c)\n",
    "\n",
    "log_expected_ut_c = exp_ut3_c\n",
    "\n",
    "#theta vector (1 row x 30 columns)\n",
    "\n",
    "gamma = np.reshape(gamma_def, (gamma_def.size,1))\n",
    "normal_theta_draws = np.reshape(normal_theta_draws,(1, normal_theta_draws.size))\n",
    "\n",
    "theta_vec = theta_def + demog_data_s@gamma + lambda_price_def*normal_theta_draws\n",
    "#review dimensions of theta vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating differences in consumer welfare per store week, and integrating across simulations\n",
    "\n",
    "#(share_mat2.iloc[:,1:].sum(axis=1)).apply(lambda x: x*(1/ns))\n",
    "\n",
    "nsim=normal_theta_draws.shape[1]\n",
    "Mt = np.array([datapack_GMM['totcount']], ndmin=2).T\n",
    "\n",
    "i=0\n",
    "Comp_Variation_sc = np.zeros((Mt.size, 1))#[0]*log_expected_ut_c.shape[0]\n",
    "\n",
    "for i in range(log_expected_ut_c.shape[0]):\n",
    "    Comp_Variation_sc[i] = ((log_expected_ut_s[i,:]-log_expected_ut_c[i,:])/theta_vec[i,:]).sum()*(1/nsim)\n",
    "    i+=1\n",
    "\n",
    "i=0\n",
    "Comp_Variation_zc = np.zeros((Mt.size, 1))#[0]*log_expected_ut_c.shape[0]\n",
    "\n",
    "for i in range(log_expected_ut_c.shape[0]):\n",
    "    Comp_Variation_zc[i] = ((log_expected_ut_z[i,:]-log_expected_ut_c[i,:])/theta_vec[i,:]).sum()*(1/nsim)\n",
    "    i+=1\n",
    "\n",
    "#DROPPING NAN AND INF VALUES\n",
    "\n",
    "CV_CS = Comp_Variation_sc*Mt\n",
    "CV_CS = pd.DataFrame(CV_CS)\n",
    "CV_CS = CV_CS.replace([np.inf, -np.inf], np.nan)\n",
    "CV_CS = CV_CS.dropna()\n",
    "CV_CS = np.array(CV_CS)\n",
    "Comp_Var_CS = CV_CS.sum()\n",
    "\n",
    "CV_CZ = Comp_Variation_zc*Mt\n",
    "CV_CZ = pd.DataFrame(CV_CZ)\n",
    "CV_CZ = CV_CZ.replace([np.inf, -np.inf], np.nan)\n",
    "CV_CZ = CV_CZ.dropna()\n",
    "CV_CZ = np.array(CV_CZ)\n",
    "Comp_Var_CZ = CV_CZ.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compensated Variation from Chain to Store: -7583103751.111582\n",
      "Compensated Variation from Chain toZone: 39381.836989612144\n"
     ]
    }
   ],
   "source": [
    "print(\"Compensated Variation from Chain to Store:\",Comp_Var_CS)\n",
    "print(\"Compensated Variation from Chain toZone:\",Comp_Var_CZ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
